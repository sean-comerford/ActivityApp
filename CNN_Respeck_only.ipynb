{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzd9Z9OZxNvd"
   },
   "source": [
    "# **Machine Learning Model**\n",
    "\n",
    "This notebook implements a convolutional neural network to recognise different physical activities from Respeck sensor data. The dataset includes multiple 30-second recordings of various physical activities (e.g., ascending stairs, shuffle walking, sitting-standing) stored in separate CSV files for each activity.\n",
    "\n",
    "This model will be deployed inside the Android app for live classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXyHZD1A0X7J"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "s2B8Hymdj1Sg"
   },
   "outputs": [],
   "source": [
    "# Importing libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icbrBf1Kl6vp"
   },
   "source": [
    "# Reading Files\n",
    "Reading files from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pTsJd33Kl44J"
   },
   "outputs": [],
   "source": [
    "# Path to Respeck data\n",
    "your_dataset_path = \"./PDIoT2324/Respeck/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOTe3o9Il4ST"
   },
   "source": [
    "This line uses the glob module to find all file paths that match a specified pattern. The 'glob.glob()' function returns a list of file paths that match the given pattern. `your_dataset_path` should be the directory where your dataset files are located.\n",
    "\n",
    "The `*` is a wildcard character that matches any string of characters,  so this pattern retrieves all folders in the 'your_dataset_path' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4izGxKkllz6",
    "outputId": "49f7031e-36ae-454a-a8dc-4a7e92243315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PDIoT2324/Respeck\\\\s100_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_hyperventilating.csv',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(your_dataset_path + \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities and Social Signals Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activities and social signals with corresponding labels\n",
    "# Each key is the name of the physical activity, and the corresponding value is the numeric label\n",
    "# These labels will be used as the target variable for classification\n",
    "activities_dict = {\n",
    "    'ascending': 0,\n",
    "    'shuffleWalking': 1,\n",
    "    'sittingStanding': 2,\n",
    "    'miscMovement': 3,\n",
    "    'normalWalking': 4,\n",
    "    'lyingBack': 5,\n",
    "    'lyingLeft': 6,\n",
    "    'lyingRight': 7,\n",
    "    'lyingStomach': 8,\n",
    "    'descending': 9,\n",
    "    'running': 10\n",
    "}\n",
    "\n",
    "social_signals_dict = {\n",
    "    'breathingNormal': 0,\n",
    "    'coughing': 1,\n",
    "    'hyperventilating': 2,\n",
    "    'other': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7eNuiHKmBuT"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zdg12YooOJF"
   },
   "source": [
    "## Load list of files in an activity folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b_ZtuAb64ZsD"
   },
   "outputs": [],
   "source": [
    "def load_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load all CSV files from a folder, extract activity and social signal information,\n",
    "    and return a list of file paths along with combined labels and file information.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing CSV files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - list: A list of file paths for all CSV files in the folder.\n",
    "        - list: A list of combined labels (activity and social signal) for each file.\n",
    "        - dict: A dictionary containing file information with activity and social signal labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise an empty list to store the full file paths of the CSV files\n",
    "    file_paths = []\n",
    "\n",
    "    # Initialise an empty dictionary to store the filenames and the activity and social signal labels\n",
    "    file_info = {}\n",
    "\n",
    "    # Initialise an empty list to store the combined labels of the activity and social signal to be used in stratified split of data\n",
    "    # Stratified split of data ensures that each activity-social signal combination is proportionally represented in the training and testing data\n",
    "    combined_labels = []\n",
    "\n",
    "    # Loop through all the files in the given folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        \n",
    "        # Check if the file has a .csv extension (ignores other files)\n",
    "        if file_name.endswith('.csv'):\n",
    "\n",
    "            # Inialise an empty dictionary for each file to store the activity and social signal labels\n",
    "            file_info[file_name] = {}\n",
    "\n",
    "            # Split the file name by underscores to extract activity and social signal information\n",
    "            parts = file_name.split(\"_\")\n",
    "            \n",
    "            # Extract the activity from the file name\n",
    "            activity = parts[2]\n",
    "\n",
    "            # Add activity label to the file_info dictionary\n",
    "            if activity == \"sitting\" or activity == \"standing\":\n",
    "                file_info[file_name]['activity_label'] = activities_dict[\"sittingStanding\"]\n",
    "            else:\n",
    "                file_info[file_name]['activity_label'] = activities_dict[activity]\n",
    "            \n",
    "            # Extract the social signal from the file name, without the .csv extension\n",
    "            social_signal = parts[3].split(\".\")[0]\n",
    "\n",
    "            # Add social signal label to the file_info dictionary\n",
    "            if social_signal == \"laughing\" or social_signal == \"eating\" or social_signal == \"talking\" or social_signal == \"singing\":\n",
    "                file_info[file_name]['social_signal_label'] = social_signals_dict[\"other\"]\n",
    "            else:\n",
    "                file_info[file_name]['social_signal_label'] = social_signals_dict[social_signal]\n",
    "            \n",
    "            # Combine the activity and social signal to create a unique label\n",
    "            combined_label = activity + \"_\" + social_signal\n",
    "\n",
    "            # Append the combined label to the combined_labels list\n",
    "            combined_labels.append(combined_label)\n",
    "\n",
    "            # Construct the full file path by joining the folder path and the file name'\n",
    "            full_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Append the full file path to the file_paths list\n",
    "            file_paths.append(full_file_path)\n",
    "\n",
    "    # Return the complete list of CSV file paths\n",
    "    return file_paths, combined_labels, file_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUGBeBBn_L8"
   },
   "source": [
    "## Train and test set split from list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2SzHoQz2NH3v"
   },
   "outputs": [],
   "source": [
    "def split_files(file_list, combined_labels, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the list of file paths into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): A list of file paths for all CSV files.\n",
    "    combined_labels (list): A list of combined labels (activity and social signal) for each file.\n",
    "    test_size (float, optional): The proportion of the dataset to include in the test split. Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - list: Training file paths.\n",
    "        - list: Testing file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the file list into training and test sets using train_test_split from scikit-learn\n",
    "    # test_size defines the proportion of the data to use as the test set (default is 20%)\n",
    "    # shuffle=True ensures that the files are shuffled randomly before splitting\n",
    "    # stratify is used to ensure that the proportion of each class is the same in both the training and testing sets\n",
    "    train_files, test_files = train_test_split(file_list, test_size=test_size, stratify = combined_labels, shuffle=True, random_state=42)\n",
    "\n",
    "    # Return the train and test file lists\n",
    "    return train_files, test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J7-zQgZzP19"
   },
   "source": [
    "## Sliding Window\n",
    "\n",
    "In time series Activity Recognition, a sliding window is a commonly used technique to segment continuous sensor data (such as accelerometer readings) into smaller, fixed-length overlapping or non-overlapping time intervals, or windows. Each window contains a sequence of sensor measurements that represent a short period of time, and this segmented data is used to extract features or make predictions about the activity happening within that window.\n",
    "\n",
    "### Key Concepts of a Sliding Window\n",
    "1.   **Window Size:** This refers to the length of each segment or window, typically defined in terms of the number of time steps or the duration (e.g., 2 seconds). The window size should be chosen carefully to capture enough information about the activity without making the window too large.\n",
    "2.   **Step Size:** The step size determines how far the window moves forward after each step. If the step size is smaller than the window size, the windows will overlap. For example, if the window size is 5 seconds and the step size is 2 seconds, there will be a 3-second overlap between consecutive windows. Overlapping windows provide more data for analysis and can help smooth out predictions by capturing transitional activities.\n",
    "3.   **Non-Overlapping Windows:** If the step size is equal to the window size, the windows do not overlap. This method provides distinct segments of data but may miss transitional phases between activities.\n",
    "\n",
    "### Why Sliding Windows for Activity Recognition?\n",
    "\n",
    "* Segmentation of Continuous Data: Activity recognition systems work with continuous streams of sensor data, and the sliding window helps segment these into manageable pieces to classify activities within specific intervals.\n",
    "\n",
    "* Context Capturing: Human activities are often complex and spread across time. By using a sliding window, you can capture context across a short duration, which may include transitions or small fluctuations in the activity (e.g., a person moving from sitting to standing).\n",
    "\n",
    "* Feature Extraction: Within each window, features such as mean, variance, frequency domain features, etc., can be extracted to help classify the activity.\n",
    "\n",
    "* Real-Time Recognition: In real-time systems, the sliding window allows for continuous monitoring and updating of predictions as new data arrives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "u3SuHww6MpEx"
   },
   "outputs": [],
   "source": [
    "def load_and_apply_sliding_windows(file_path, window_size, step_size, file_info):\n",
    "    \"\"\"\n",
    "    Load the data from each file, apply sliding windows, and return the windows and labels.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths to CSV files. Each file contains sensor data.\n",
    "    window_size (int): The size of each sliding window (number of time steps).\n",
    "    step_size (int): The step size (stride) between consecutive windows.\n",
    "    file_info (dict): Dictionary containing file information with activity and social signal labels.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - windows (numpy.ndarray): A 3D array of sliding windows, where each window has the shape\n",
    "                                   (num_windows, window_size, num_features).\n",
    "        - activity_labels (numpy.ndarray): A 1D array of activity labels, where each label corresponds to a sliding window.\n",
    "        - social_signal_labels (numpy.ndarray): A 1D array of social signal labels, where each label corresponds to a sliding window.\n",
    "    \"\"\"\n",
    "    # Initialise lists to store sliding windows and their corresponding labels\n",
    "    windows = []\n",
    "    activity_labels = []\n",
    "    social_signal_labels = []\n",
    "    file_number = 0\n",
    "\n",
    "    \n",
    "    # Loop through each file in the provided file path\n",
    "    for file in file_path:\n",
    "\n",
    "        # Extract the activity and social signal labels from the file_info dictionary\n",
    "        activity_label = file_info[os.path.basename(file)]['activity_label']\n",
    "        social_signal_label = file_info[os.path.basename(file)]['social_signal_label']\n",
    "\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        data = pd.read_csv(file)   \n",
    "\n",
    "\n",
    "        # Select the columns containing the necessary sensor data (acceleration readings)\n",
    "        # These columns might vary depending on your dataset's structure\n",
    "        data = data[['accel_x', 'accel_y', 'accel_z']]\n",
    "        \n",
    "        # Convert the DataFrame into a numpy array for faster processing in the sliding window operation\n",
    "        data = data.to_numpy()\n",
    "\n",
    "        \n",
    "        # Get the number of samples (rows) and features (columns) in the data\n",
    "        num_samples, num_features = data.shape\n",
    "        \n",
    "        # Apply sliding windows to the data\n",
    "        # The range function defines the start of each window, moving step_size increments at a time\n",
    "        for i in range(0, num_samples - window_size + 1, step_size):\n",
    "            # Extract a window of size 'window_size' from the current position 'i'\n",
    "            window = data[i:i + window_size, :]\n",
    "\n",
    "            # Append the window to the windows list\n",
    "            windows.append(window)\n",
    "\n",
    "            # Assign the activity label to the window and append it to the activity labels list\n",
    "            activity_labels.append(activity_label)\n",
    "\n",
    "            # Assign the social signal label to the window and append it to the social signal labels list\n",
    "            social_signal_labels.append(social_signal_label)\n",
    "\n",
    "    # Convert the lists of windows and labels into numpy arrays for efficient numerical operations\n",
    "    return np.array(windows), np.array(activity_labels), np.array(social_signal_labels) \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Ku5P4Lm8QA"
   },
   "source": [
    "## Load and Split Train Test for Each Activity Folder\n",
    "\n",
    "This function processes the sensor data for a specific activity, such as 'walking' or 'running', stored in its respective folder. It splits the data into training and testing sets, applies sliding windows, and labels the windows with the corresponding activity. This function can be used repeatedly for each activity to process and prepare data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zBVvTBi7N_fh"
   },
   "outputs": [],
   "source": [
    "def process_activity(dataset_path, window_size=50, step_size=50, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Processes an activity folder by loading the file list, splitting them into\n",
    "    train and test sets, and applying sliding windows to the files.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Base path where the activity folders are located.\n",
    "        window_size (int): Size of the sliding window, i.e., the number of time steps included in each window.\n",
    "                           Default is 50.\n",
    "        step_size (int): Step size for the sliding window, i.e., how far the window moves along the data.\n",
    "                         Default is 50 (no overlap between windows).\n",
    "        test_size (float): Proportion of files to use for testing. Default is 0.2, meaning 20% of files will\n",
    "                           be allocated to the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - train_windows (numpy.ndarray): Sliding windows from the training files.\n",
    "            - train_activity_labels (numpy.ndarray): Corresponding activity labels for the training windows.\n",
    "            - train_social_signal_labels (numpy.ndarray): Corresponding social signal labels for the training windows.\n",
    "            - test_windows (numpy.ndarray): Sliding windows from the test files.\n",
    "            - test_activity_labels (numpy.ndarray): Corresponding activity labels for the test windows.\n",
    "            - test_social_signal_labels (numpy.ndarray): Corresponding social signal labels for the test windows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all CSV file paths for the given activity from the folder\n",
    "    file_paths, combined_labels, file_info = load_files_from_folder(dataset_path)\n",
    "\n",
    "    # Split the file list into training and testing sets\n",
    "    # train_files: files used for training\n",
    "    # test_files: files used for testing\n",
    "    train_files, test_files = split_files(file_paths, combined_labels, test_size=test_size)\n",
    "\n",
    "    # Apply sliding windows to the training files\n",
    "    # The function 'load_and_apply_sliding_windows' returns the sliding windows (segments) and their corresponding activity and social signal labels\n",
    "    train_windows, train_activity_labels, train_social_signal_labels = load_and_apply_sliding_windows(train_files, window_size, step_size, file_info)\n",
    "\n",
    "    # Apply sliding windows to the testing files\n",
    "    test_windows, test_activity_labels, test_social_signal_labels = load_and_apply_sliding_windows(test_files, window_size, step_size, file_info)\n",
    "\n",
    "    # Return the sliding windows and their labels for both training and testing sets\n",
    "    return train_windows, train_activity_labels, train_social_signal_labels, test_windows, test_activity_labels, test_social_signal_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wv1PuOLgUV8"
   },
   "source": [
    "## 1D CNN Model\n",
    "\n",
    "This function, `build_1d_cnn_model`, creates and compiles a 1D Convolutional Neural Network (CNN) for multi-label classification tasks.\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "Input Parameters\n",
    "* `input_shape`: Specifies the shape of the input data. It represents (timesteps, features), where timesteps refer to the length of the time series (e.g., 50 windows), and features represent the number of measurements in each time step (e.g., accelerometer readings).\n",
    "* `num_activity_classes`: The number of output classes for the activity classification problem.\n",
    "* `num_social_signal_classes`: The number of output classes for the social signal classification problem.\n",
    "\n",
    "Returns\n",
    "* The function returns a compiled 1D CNN model with two outputs that is ready to be trained on your data.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Function Breakdown\n",
    "1. **Model Initialization:**\n",
    "    * `inputs = Input(shape=input_shape)`: Initializes the input layer with the specified shape.\n",
    "2. **First Convolutional Layer:**\n",
    "    * `Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)`\n",
    "        * This is the first 1D convolutional layer.\n",
    "        * `filters=64`: The layer applies 64 filters (or kernels) over the input data.\n",
    "        * `kernel_size=3`: Each filter will cover 3 timesteps at a time (a window of 3).\n",
    "        * `activation='relu'`: The Rectified Linear Unit (ReLU) activation function introduces non-linearity and helps the model learn complex patterns.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: This pooling layer reduces the dimensionality of the data by taking the maximum value from each 2-timestep window (`pool_size=2`).\n",
    "3. **Second Convolutional Layer:**\n",
    "    * `Conv1D(filters=128, kernel_size=3, activation='relu')(x)`\n",
    "        * This is the second convolutional layer, similar to the first, but with 128 filters.\n",
    "        * `kernel_size=3` and `activation='relu'` function in the same way as the first Conv1D layer.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: Another pooling layer to downsample the output, further reducing the data’s dimensionality.\n",
    "4. **Flattening Layer:**\n",
    "    * `Flatten()(x)`: Converts the 2D output of the convolutional and pooling layers into a 1D vector.\n",
    "5. **Fully Connected Layer:**\n",
    "    * `Dense(128, activation='relu')(x)`: This is a fully connected layer with 128 units/neurons.\n",
    "6. **Dropout Layer:**\n",
    "    * `Dropout(0.5)(x)`: This layer randomly sets 50% of the neurons to zero during training to prevent overfitting.\n",
    "7. **Output Layer for Activity Classification:**\n",
    "    * `Dense(num_activity_classes, activation='softmax', name='activity_output')(x)`: This is the output layer for activity classification with `num_activity_classes` neurons.\n",
    "8. **Output Layer for Social Signal Classification:**\n",
    "    * `Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(x)`: This is the output layer for social signal classification with `num_social_signal_classes` neurons.\n",
    "9. **Model Definition:**\n",
    "    * `model = Model(inputs=inputs, outputs=[activity_output, social_signal_output])`: Defines the model with two outputs.\n",
    "10. **Compiling the Model:**\n",
    "    * `model.compile(optimizer='adam', loss={'activity_output': 'categorical_crossentropy', 'social_signal_output': 'categorical_crossentropy'}, metrics={'activity_output': 'accuracy', 'social_signal_output': 'accuracy'})`\n",
    "        * Optimizer: 'adam': Adam is an optimization algorithm that adjusts the learning rate during training to improve performance.\n",
    "        * Loss: 'categorical_crossentropy': This loss function is used for multi-class classification problems where the target variable is one-hot encoded.\n",
    "        * Metrics: ['accuracy']: The accuracy metric is used to evaluate the model’s performance during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sCOkh99EOg8t"
   },
   "outputs": [],
   "source": [
    "def build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes):\n",
    "    \"\"\"\n",
    "    Builds and compiles a 1D CNN model for multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (timesteps, features).\n",
    "        num_activity_classes (int): The number of output activity classes.\n",
    "        num_social_signal_classes (int): The number of output social signal classes.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): Compiled 1D CNN model with two outputs.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First Conv1D layer\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Second Conv1D layer\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Flatten the output from the convolutional layers\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Dropout layer for regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer for activity classification\n",
    "    activity_output = Dense(num_activity_classes, activation='softmax', name='activity_output')(x)\n",
    "\n",
    "    # Output layer for social signal classification\n",
    "    social_signal_output = Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(x)\n",
    "\n",
    "    # Define the model with two outputs\n",
    "    model = Model(inputs=inputs, outputs=[activity_output, social_signal_output])\n",
    "\n",
    "    # Compile the model with two separate losses\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'activity_output': 'categorical_crossentropy', 'social_signal_output': 'categorical_crossentropy'},\n",
    "                  metrics={'activity_output': 'accuracy', 'social_signal_output': 'accuracy'})\n",
    "\n",
    "    # Print a detailed summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HurfE6lmOjQT"
   },
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLs1eacYoa_S"
   },
   "source": [
    "## Step 1: Prepare and Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdGR352hph4X"
   },
   "source": [
    "Now the training and testing data will be created by calling the function `process_activity`. The `process_activity` function is used to generate sliding windows and labels for the training and testing sets.\n",
    "* `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
    "* `y_train_activity` and `y_train_social_signal` are 1D arrays of activity and social signal labels for the training set.\n",
    "* `y_test_activity` and `y_test_social_signal` are 1D arrays of activity and social signal labels for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OtpVBr4Fpq_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48575 train windows generated with 48575 activity labels and 48575 social signal labels\n",
      "12154 test windows generated with 12154 activity labels and 12154 social signal labels\n"
     ]
    }
   ],
   "source": [
    "# Generate the sliding windows along with activity and social signal labels for training and testing sets\n",
    "X_train, y_train_activity, y_train_social_signal, X_test, y_test_activity, y_test_social_signal = process_activity(your_dataset_path, test_size=0.2, window_size=50, step_size=50)\n",
    "print(f\"{len(X_train)} train windows generated with {len(y_train_activity)} activity labels and {len(y_train_social_signal)} social signal labels\")\n",
    "print(f\"{len(X_test)} test windows generated with {len(y_test_activity)} activity labels and {len(y_test_social_signal)} social signal labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training and testing sets generated by the `process_activity` function are checked to see that they have the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymA3yh7YFKix",
    "outputId": "3682e518-cfe7-454a-e719-664a4c435732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (48575, 50, 3), y_train_activity shape: (48575,), y_train_social_signal shape: (48575,)\n",
      "X_test shape: (12154, 50, 3), y_test_activity shape: (12154,), y_test_social_signal shape: (12154,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
    "print(f\"X_train shape: {X_train.shape}, y_train_activity shape: {y_train_activity.shape}, y_train_social_signal shape: {y_train_social_signal.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test_activity shape: {y_test_activity.shape}, y_test_social_signal shape: {y_test_social_signal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yQGU1vwIQdz"
   },
   "source": [
    "### One-Hot Encode Labels (for multi-class classification)\n",
    "Since there are more than two classes, the labels must be one-hot encoded, especially as the model will use categorical cross-entropy loss.\n",
    "\n",
    "One-Hot Encoding converts categorical labels into binary vectors (one-hot encoded format). Each class label is represented as a binary vector with 1 for the correct class and 0 for others. This is necessary for training models that use categorical_crossentropy as the loss function, such as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9b2J1EVdHj0U"
   },
   "outputs": [],
   "source": [
    "# Initialise the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the OneHotEncoder on the training activity labels and transform them to one-hot encoded format\n",
    "y_train_activity_one_hot = encoder.fit_transform(y_train_activity.reshape(-1, 1))\n",
    "\n",
    "# Transform the test activity labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_activity_one_hot = encoder.transform(y_test_activity.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Fit the OneHotEncoder on the training social signal labels and transform them to one-hot encoded format\n",
    "y_train_social_signal_one_hot = encoder.fit_transform(y_train_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Transform the test social signal labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_social_signal_one_hot = encoder.transform(y_test_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Explanation:\n",
    "# - y_train_activity_one_hot, y_train_social_signal_one_hot, y_test_activity_one_hot and y_test_social_signal_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
    "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
    "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlnbOVr0rDbV",
    "outputId": "98ddbd62-4d6c-41ba-ac94-00d74a30f3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_activity_one_hot shape: (48575, 11), y_train_social_signal_one_hot shape: (48575, 4), y_test_activity_one_hot shape: (12154, 11), y_test_social_signal_one_hot shape: (12154, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
    "print(f\"y_train_activity_one_hot shape: {y_train_activity_one_hot.shape}, y_train_social_signal_one_hot shape: {y_train_social_signal_one_hot.shape}, y_test_activity_one_hot shape: {y_test_activity_one_hot.shape}, y_test_social_signal_one_hot shape: {y_test_social_signal_one_hot.shape}\")\n",
    "\n",
    "# Explanation of shapes:\n",
    "# - The shape of y_train_activity_one_hot will be (num_samples, num_classes), where:\n",
    "#     - num_samples is the number of training windows.\n",
    "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
    "# - Similarly, y_test_activity_one_hot will have the same number of columns (num_classes) as y_train_activity_one_hot but will have fewer rows (corresponding to the number of test windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEhUxZzzJzzI"
   },
   "source": [
    "## Step 2: Build the 1D-CNN Model\n",
    "Call our `build_1d_cnn_model` function to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "4sDZWZH_KKBD",
    "outputId": "12cc6048-0921-414c-d2d7-b8d5268a8196"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the input shape for the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Determine the number of output classes (num_classes)\n",
    "num_activity_classes = y_train_activity_one_hot.shape[1]\n",
    "num_social_signal_classes = y_train_social_signal_one_hot.shape[1]\n",
    "\n",
    "# Build and compile the model\n",
    "# The function will return a compiled model ready for training\n",
    "model = build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1-SHEmtKM0D"
   },
   "source": [
    "## Step 3: Train the CNN Model\n",
    "\n",
    "Train the 1D CNN model using the training data and validate on the test data. The model will learn to map input sliding windows to their corresponding activity and social signal labels.\n",
    "\n",
    "`model.fit()` is used to train the neural network model. It takes several parameters:\n",
    "* `X_train`: The input training data (sliding windows), with shape (num_samples, window_size, num_features).\n",
    "* `{'activity_output': y_train_activity_one_hot, 'social_signal_output': y_train_social_signal_one_hot}`: The corresponding one-hot encoded labels for the training data, with shape (num_samples, num_classes).\n",
    "* `epochs`: Number of times the entire training dataset is passed through the model. In this case, we are training for 20 epochs, meaning the model will see the entire training set 20 times.\n",
    "* `batch_size`: Number of samples processed before the model's weights are updated. Here, the batch size is set to 32, meaning the model will process 32 samples at a time before updating its parameters.\n",
    "* `validation_data`: This parameter allows us to evaluate the model's performance on the test data after each epoch. It takes the test data and corresponding one-hot encoded test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4zICRasKPsT",
    "outputId": "c2c4bde2-1417-4c96-e25b-8e4f3d039bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - activity_output_accuracy: 0.8688 - activity_output_loss: 0.5125 - loss: 1.6992 - social_signal_output_accuracy: 0.5182 - social_signal_output_loss: 1.1867 - val_activity_output_accuracy: 0.9084 - val_activity_output_loss: 0.2955 - val_loss: 1.3331 - val_social_signal_output_accuracy: 0.5863 - val_social_signal_output_loss: 1.0371\n",
      "Epoch 2/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - activity_output_accuracy: 0.9165 - activity_output_loss: 0.2625 - loss: 1.2478 - social_signal_output_accuracy: 0.5904 - social_signal_output_loss: 0.9854 - val_activity_output_accuracy: 0.9264 - val_activity_output_loss: 0.2580 - val_loss: 1.1815 - val_social_signal_output_accuracy: 0.6052 - val_social_signal_output_loss: 0.9230\n",
      "Epoch 3/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9312 - activity_output_loss: 0.2186 - loss: 1.1519 - social_signal_output_accuracy: 0.5971 - social_signal_output_loss: 0.9333 - val_activity_output_accuracy: 0.9348 - val_activity_output_loss: 0.2415 - val_loss: 1.1366 - val_social_signal_output_accuracy: 0.6058 - val_social_signal_output_loss: 0.8947\n",
      "Epoch 4/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9423 - activity_output_loss: 0.1869 - loss: 1.0968 - social_signal_output_accuracy: 0.5963 - social_signal_output_loss: 0.9098 - val_activity_output_accuracy: 0.9458 - val_activity_output_loss: 0.2200 - val_loss: 1.0843 - val_social_signal_output_accuracy: 0.6122 - val_social_signal_output_loss: 0.8640\n",
      "Epoch 5/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9445 - activity_output_loss: 0.1715 - loss: 1.0591 - social_signal_output_accuracy: 0.6072 - social_signal_output_loss: 0.8877 - val_activity_output_accuracy: 0.9352 - val_activity_output_loss: 0.2556 - val_loss: 1.1601 - val_social_signal_output_accuracy: 0.5936 - val_social_signal_output_loss: 0.9040\n",
      "Epoch 6/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9483 - activity_output_loss: 0.1616 - loss: 1.0268 - social_signal_output_accuracy: 0.6121 - social_signal_output_loss: 0.8651 - val_activity_output_accuracy: 0.9460 - val_activity_output_loss: 0.2447 - val_loss: 1.1084 - val_social_signal_output_accuracy: 0.6117 - val_social_signal_output_loss: 0.8634\n",
      "Epoch 7/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9532 - activity_output_loss: 0.1450 - loss: 1.0018 - social_signal_output_accuracy: 0.6125 - social_signal_output_loss: 0.8569 - val_activity_output_accuracy: 0.9473 - val_activity_output_loss: 0.2540 - val_loss: 1.0966 - val_social_signal_output_accuracy: 0.6130 - val_social_signal_output_loss: 0.8423\n",
      "Epoch 8/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9590 - activity_output_loss: 0.1315 - loss: 0.9799 - social_signal_output_accuracy: 0.6155 - social_signal_output_loss: 0.8484 - val_activity_output_accuracy: 0.9536 - val_activity_output_loss: 0.2634 - val_loss: 1.1117 - val_social_signal_output_accuracy: 0.6139 - val_social_signal_output_loss: 0.8479\n",
      "Epoch 9/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9595 - activity_output_loss: 0.1286 - loss: 0.9602 - social_signal_output_accuracy: 0.6259 - social_signal_output_loss: 0.8316 - val_activity_output_accuracy: 0.9498 - val_activity_output_loss: 0.2691 - val_loss: 1.1144 - val_social_signal_output_accuracy: 0.6084 - val_social_signal_output_loss: 0.8450\n",
      "Epoch 10/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9627 - activity_output_loss: 0.1169 - loss: 0.9338 - social_signal_output_accuracy: 0.6272 - social_signal_output_loss: 0.8169 - val_activity_output_accuracy: 0.9519 - val_activity_output_loss: 0.3043 - val_loss: 1.1780 - val_social_signal_output_accuracy: 0.6221 - val_social_signal_output_loss: 0.8733\n",
      "Epoch 11/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9660 - activity_output_loss: 0.1116 - loss: 0.9107 - social_signal_output_accuracy: 0.6308 - social_signal_output_loss: 0.7991 - val_activity_output_accuracy: 0.9539 - val_activity_output_loss: 0.2848 - val_loss: 1.1385 - val_social_signal_output_accuracy: 0.6188 - val_social_signal_output_loss: 0.8533\n",
      "Epoch 12/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - activity_output_accuracy: 0.9678 - activity_output_loss: 0.1053 - loss: 0.8993 - social_signal_output_accuracy: 0.6370 - social_signal_output_loss: 0.7940 - val_activity_output_accuracy: 0.9557 - val_activity_output_loss: 0.2769 - val_loss: 1.1146 - val_social_signal_output_accuracy: 0.6331 - val_social_signal_output_loss: 0.8373\n",
      "Epoch 13/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9694 - activity_output_loss: 0.0972 - loss: 0.8732 - social_signal_output_accuracy: 0.6434 - social_signal_output_loss: 0.7760 - val_activity_output_accuracy: 0.9510 - val_activity_output_loss: 0.3073 - val_loss: 1.1222 - val_social_signal_output_accuracy: 0.6368 - val_social_signal_output_loss: 0.8144\n",
      "Epoch 14/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9700 - activity_output_loss: 0.0937 - loss: 0.8435 - social_signal_output_accuracy: 0.6588 - social_signal_output_loss: 0.7498 - val_activity_output_accuracy: 0.9547 - val_activity_output_loss: 0.3106 - val_loss: 1.1211 - val_social_signal_output_accuracy: 0.6479 - val_social_signal_output_loss: 0.8101\n",
      "Epoch 15/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9726 - activity_output_loss: 0.0880 - loss: 0.8335 - social_signal_output_accuracy: 0.6558 - social_signal_output_loss: 0.7455 - val_activity_output_accuracy: 0.9590 - val_activity_output_loss: 0.2868 - val_loss: 1.0747 - val_social_signal_output_accuracy: 0.6580 - val_social_signal_output_loss: 0.7875\n",
      "Epoch 16/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9765 - activity_output_loss: 0.0808 - loss: 0.8110 - social_signal_output_accuracy: 0.6699 - social_signal_output_loss: 0.7302 - val_activity_output_accuracy: 0.9566 - val_activity_output_loss: 0.3381 - val_loss: 1.1429 - val_social_signal_output_accuracy: 0.6508 - val_social_signal_output_loss: 0.8043\n",
      "Epoch 17/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9768 - activity_output_loss: 0.0803 - loss: 0.8027 - social_signal_output_accuracy: 0.6706 - social_signal_output_loss: 0.7225 - val_activity_output_accuracy: 0.9589 - val_activity_output_loss: 0.3336 - val_loss: 1.1307 - val_social_signal_output_accuracy: 0.6609 - val_social_signal_output_loss: 0.7967\n",
      "Epoch 18/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9774 - activity_output_loss: 0.0725 - loss: 0.7746 - social_signal_output_accuracy: 0.6811 - social_signal_output_loss: 0.7021 - val_activity_output_accuracy: 0.9539 - val_activity_output_loss: 0.3448 - val_loss: 1.1532 - val_social_signal_output_accuracy: 0.6626 - val_social_signal_output_loss: 0.8079\n",
      "Epoch 19/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - activity_output_accuracy: 0.9778 - activity_output_loss: 0.0713 - loss: 0.7729 - social_signal_output_accuracy: 0.6790 - social_signal_output_loss: 0.7016 - val_activity_output_accuracy: 0.9541 - val_activity_output_loss: 0.3728 - val_loss: 1.1739 - val_social_signal_output_accuracy: 0.6602 - val_social_signal_output_loss: 0.8006\n",
      "Epoch 20/20\n",
      "\u001b[1m1518/1518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9786 - activity_output_loss: 0.0695 - loss: 0.7648 - social_signal_output_accuracy: 0.6867 - social_signal_output_loss: 0.6952 - val_activity_output_accuracy: 0.9589 - val_activity_output_loss: 0.3766 - val_loss: 1.1580 - val_social_signal_output_accuracy: 0.6683 - val_social_signal_output_loss: 0.7811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,  # Input data\n",
    "    {'activity_output': y_train_activity_one_hot, 'social_signal_output': y_train_social_signal_one_hot},  # Target labels\n",
    "    epochs=20, # Train the model for 20 epochs\n",
    "    batch_size=32, # Use a batch size of 32\n",
    "    validation_data=(X_test, {'activity_output': y_test_activity_one_hot, 'social_signal_output': y_test_social_signal_one_hot}) # Validate the test set after each epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_accuracy` is the accuracy of the model on the validation data (in this case X_test, y_test_activity_one_hot and y_test_social_signal_one_hot). The `accuracy` is the training accuracy for the current epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrSPBPh4KcBn"
   },
   "source": [
    "## Step 4: Evaluate the Model\n",
    "After training, the model is evaluated on the test set. This is done with a classification report and 5-Fold Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UB2Bi7ieKelv",
    "outputId": "de615d87-81e5-45df-f50b-60b21139fdd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Classification Report for Activity Labels:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9036    0.8333    0.8671       270\n",
      "           1     0.7552    0.5370    0.6277       270\n",
      "           2     0.9737    0.9923    0.9829      3887\n",
      "           3     0.6458    0.6889    0.6667       270\n",
      "           4     0.7348    0.8099    0.7705       284\n",
      "           5     0.9765    1.0000    0.9881      1659\n",
      "           6     0.9898    0.9946    0.9922      1660\n",
      "           7     0.9975    0.9729    0.9850      1658\n",
      "           8     0.9868    0.9897    0.9883      1658\n",
      "           9     0.8125    0.8246    0.8185       268\n",
      "          10     0.9741    0.8370    0.9004       270\n",
      "\n",
      "    accuracy                         0.9589     12154\n",
      "   macro avg     0.8864    0.8618    0.8716     12154\n",
      "weighted avg     0.9585    0.9589    0.9580     12154\n",
      "\n",
      "Classification Report for Social Signal Labels:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7947    0.7063    0.7479      3337\n",
      "           1     0.6301    0.6770    0.6527      1613\n",
      "           2     0.5267    0.1936    0.2832      1632\n",
      "           3     0.6357    0.7821    0.7014      5572\n",
      "\n",
      "    accuracy                         0.6683     12154\n",
      "   macro avg     0.6468    0.5898    0.5963     12154\n",
      "weighted avg     0.6640    0.6683    0.6515     12154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities for the test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Seperate the predictions for activity and social signal\n",
    "y_pred_probs_activity = y_pred_probs[0]\n",
    "y_pred_probs_social_signal = y_pred_probs[1]\n",
    "\n",
    "# Convert the predicted probabilities to class labels (taking the argmax of the probabilities)\n",
    "y_pred_classes_activity = np.argmax(y_pred_probs_activity, axis=1)\n",
    "y_pred_classes_social_signal = np.argmax(y_pred_probs_social_signal, axis=1)\n",
    "\n",
    "# Convert the true test labels from one-hot encoding back to class labels\n",
    "y_true_classes_activity = np.argmax(y_test_activity_one_hot, axis=1)\n",
    "y_true_classes_social_signal = np.argmax(y_test_social_signal_oane_hot, axis=1)\n",
    "\n",
    "# Generate the classification report for activity labels\n",
    "report_activity = classification_report(y_true_classes_activity, y_pred_classes_activity, digits=4)\n",
    "print(\"Classification Report for Activity Labels:\")\n",
    "print(report_activity)\n",
    "\n",
    "# Generate the classification report for social signal labels\n",
    "report_social_signal = classification_report(y_true_classes_social_signal, y_pred_classes_social_signal, digits=4)\n",
    "print(\"Classification Report for Social Signal Labels:\")\n",
    "print(report_social_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.8607 - activity_output_loss: 0.5476 - loss: 1.7491 - social_signal_output_accuracy: 0.5100 - social_signal_output_loss: 1.2015 - val_activity_output_accuracy: 0.9180 - val_activity_output_loss: 0.2627 - val_loss: 1.2829 - val_social_signal_output_accuracy: 0.5843 - val_social_signal_output_loss: 1.0200\n",
      "Epoch 2/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9125 - activity_output_loss: 0.2783 - loss: 1.2964 - social_signal_output_accuracy: 0.5890 - social_signal_output_loss: 1.0181 - val_activity_output_accuracy: 0.9268 - val_activity_output_loss: 0.2200 - val_loss: 1.1606 - val_social_signal_output_accuracy: 0.6037 - val_social_signal_output_loss: 0.9401\n",
      "Epoch 3/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9263 - activity_output_loss: 0.2311 - loss: 1.1799 - social_signal_output_accuracy: 0.5938 - social_signal_output_loss: 0.9488 - val_activity_output_accuracy: 0.9406 - val_activity_output_loss: 0.1856 - val_loss: 1.0869 - val_social_signal_output_accuracy: 0.6093 - val_social_signal_output_loss: 0.9009\n",
      "Epoch 4/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9382 - activity_output_loss: 0.1961 - loss: 1.1184 - social_signal_output_accuracy: 0.5987 - social_signal_output_loss: 0.9223 - val_activity_output_accuracy: 0.9442 - val_activity_output_loss: 0.1643 - val_loss: 1.0370 - val_social_signal_output_accuracy: 0.6117 - val_social_signal_output_loss: 0.8721\n",
      "Epoch 5/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9420 - activity_output_loss: 0.1854 - loss: 1.0939 - social_signal_output_accuracy: 0.6024 - social_signal_output_loss: 0.9085 - val_activity_output_accuracy: 0.9506 - val_activity_output_loss: 0.1518 - val_loss: 1.0234 - val_social_signal_output_accuracy: 0.6080 - val_social_signal_output_loss: 0.8710\n",
      "Epoch 6/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9471 - activity_output_loss: 0.1618 - loss: 1.0565 - social_signal_output_accuracy: 0.5997 - social_signal_output_loss: 0.8947 - val_activity_output_accuracy: 0.9502 - val_activity_output_loss: 0.1430 - val_loss: 0.9742 - val_social_signal_output_accuracy: 0.6187 - val_social_signal_output_loss: 0.8307\n",
      "Epoch 7/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9497 - activity_output_loss: 0.1532 - loss: 1.0298 - social_signal_output_accuracy: 0.6042 - social_signal_output_loss: 0.8767 - val_activity_output_accuracy: 0.9544 - val_activity_output_loss: 0.1421 - val_loss: 0.9658 - val_social_signal_output_accuracy: 0.6186 - val_social_signal_output_loss: 0.8233\n",
      "Epoch 8/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9549 - activity_output_loss: 0.1412 - loss: 1.0055 - social_signal_output_accuracy: 0.6050 - social_signal_output_loss: 0.8644 - val_activity_output_accuracy: 0.9547 - val_activity_output_loss: 0.1362 - val_loss: 0.9586 - val_social_signal_output_accuracy: 0.6215 - val_social_signal_output_loss: 0.8220\n",
      "Epoch 9/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - activity_output_accuracy: 0.9582 - activity_output_loss: 0.1278 - loss: 0.9772 - social_signal_output_accuracy: 0.6070 - social_signal_output_loss: 0.8494 - val_activity_output_accuracy: 0.9610 - val_activity_output_loss: 0.1170 - val_loss: 0.9206 - val_social_signal_output_accuracy: 0.6211 - val_social_signal_output_loss: 0.8033\n",
      "Epoch 10/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9588 - activity_output_loss: 0.1204 - loss: 0.9549 - social_signal_output_accuracy: 0.6167 - social_signal_output_loss: 0.8345 - val_activity_output_accuracy: 0.9655 - val_activity_output_loss: 0.1089 - val_loss: 0.9158 - val_social_signal_output_accuracy: 0.6246 - val_social_signal_output_loss: 0.8066\n",
      "Epoch 11/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9629 - activity_output_loss: 0.1139 - loss: 0.9496 - social_signal_output_accuracy: 0.6123 - social_signal_output_loss: 0.8357 - val_activity_output_accuracy: 0.9663 - val_activity_output_loss: 0.1072 - val_loss: 0.9028 - val_social_signal_output_accuracy: 0.6316 - val_social_signal_output_loss: 0.7953\n",
      "Epoch 12/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9650 - activity_output_loss: 0.1075 - loss: 0.9321 - social_signal_output_accuracy: 0.6211 - social_signal_output_loss: 0.8246 - val_activity_output_accuracy: 0.9663 - val_activity_output_loss: 0.1096 - val_loss: 0.8993 - val_social_signal_output_accuracy: 0.6295 - val_social_signal_output_loss: 0.7895\n",
      "Epoch 13/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9675 - activity_output_loss: 0.1016 - loss: 0.9219 - social_signal_output_accuracy: 0.6188 - social_signal_output_loss: 0.8202 - val_activity_output_accuracy: 0.9675 - val_activity_output_loss: 0.0976 - val_loss: 0.8596 - val_social_signal_output_accuracy: 0.6378 - val_social_signal_output_loss: 0.7618\n",
      "Epoch 14/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9709 - activity_output_loss: 0.0923 - loss: 0.8965 - social_signal_output_accuracy: 0.6302 - social_signal_output_loss: 0.8042 - val_activity_output_accuracy: 0.9646 - val_activity_output_loss: 0.1160 - val_loss: 0.8796 - val_social_signal_output_accuracy: 0.6380 - val_social_signal_output_loss: 0.7639\n",
      "Epoch 15/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9700 - activity_output_loss: 0.0929 - loss: 0.8832 - social_signal_output_accuracy: 0.6354 - social_signal_output_loss: 0.7903 - val_activity_output_accuracy: 0.9686 - val_activity_output_loss: 0.0956 - val_loss: 0.8607 - val_social_signal_output_accuracy: 0.6454 - val_social_signal_output_loss: 0.7650\n",
      "Epoch 16/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9706 - activity_output_loss: 0.0890 - loss: 0.8768 - social_signal_output_accuracy: 0.6332 - social_signal_output_loss: 0.7878 - val_activity_output_accuracy: 0.9683 - val_activity_output_loss: 0.0986 - val_loss: 0.8570 - val_social_signal_output_accuracy: 0.6444 - val_social_signal_output_loss: 0.7589\n",
      "Epoch 17/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9740 - activity_output_loss: 0.0811 - loss: 0.8573 - social_signal_output_accuracy: 0.6430 - social_signal_output_loss: 0.7762 - val_activity_output_accuracy: 0.9703 - val_activity_output_loss: 0.0987 - val_loss: 0.8541 - val_social_signal_output_accuracy: 0.6574 - val_social_signal_output_loss: 0.7554\n",
      "Epoch 18/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9745 - activity_output_loss: 0.0802 - loss: 0.8441 - social_signal_output_accuracy: 0.6494 - social_signal_output_loss: 0.7640 - val_activity_output_accuracy: 0.9697 - val_activity_output_loss: 0.1014 - val_loss: 0.8550 - val_social_signal_output_accuracy: 0.6600 - val_social_signal_output_loss: 0.7537\n",
      "Epoch 19/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9756 - activity_output_loss: 0.0751 - loss: 0.8340 - social_signal_output_accuracy: 0.6488 - social_signal_output_loss: 0.7588 - val_activity_output_accuracy: 0.9712 - val_activity_output_loss: 0.0989 - val_loss: 0.8045 - val_social_signal_output_accuracy: 0.6715 - val_social_signal_output_loss: 0.7059\n",
      "Epoch 20/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9763 - activity_output_loss: 0.0720 - loss: 0.8172 - social_signal_output_accuracy: 0.6527 - social_signal_output_loss: 0.7452 - val_activity_output_accuracy: 0.9712 - val_activity_output_loss: 0.0993 - val_loss: 0.8058 - val_social_signal_output_accuracy: 0.6866 - val_social_signal_output_loss: 0.7066\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Completed fold 1\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - activity_output_accuracy: 0.8645 - activity_output_loss: 0.5406 - loss: 1.7391 - social_signal_output_accuracy: 0.5120 - social_signal_output_loss: 1.1985 - val_activity_output_accuracy: 0.9199 - val_activity_output_loss: 0.2636 - val_loss: 1.3191 - val_social_signal_output_accuracy: 0.5767 - val_social_signal_output_loss: 1.0558\n",
      "Epoch 2/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9130 - activity_output_loss: 0.2784 - loss: 1.3183 - social_signal_output_accuracy: 0.5809 - social_signal_output_loss: 1.0399 - val_activity_output_accuracy: 0.9340 - val_activity_output_loss: 0.2058 - val_loss: 1.2070 - val_social_signal_output_accuracy: 0.5992 - val_social_signal_output_loss: 1.0008\n",
      "Epoch 3/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9256 - activity_output_loss: 0.2352 - loss: 1.1966 - social_signal_output_accuracy: 0.5941 - social_signal_output_loss: 0.9614 - val_activity_output_accuracy: 0.9390 - val_activity_output_loss: 0.1924 - val_loss: 1.1128 - val_social_signal_output_accuracy: 0.5968 - val_social_signal_output_loss: 0.9200\n",
      "Epoch 4/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9330 - activity_output_loss: 0.2101 - loss: 1.1413 - social_signal_output_accuracy: 0.5966 - social_signal_output_loss: 0.9312 - val_activity_output_accuracy: 0.9493 - val_activity_output_loss: 0.1569 - val_loss: 1.0277 - val_social_signal_output_accuracy: 0.6095 - val_social_signal_output_loss: 0.8704\n",
      "Epoch 5/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9382 - activity_output_loss: 0.1905 - loss: 1.0972 - social_signal_output_accuracy: 0.6043 - social_signal_output_loss: 0.9067 - val_activity_output_accuracy: 0.9539 - val_activity_output_loss: 0.1399 - val_loss: 1.0065 - val_social_signal_output_accuracy: 0.6135 - val_social_signal_output_loss: 0.8663\n",
      "Epoch 6/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9448 - activity_output_loss: 0.1688 - loss: 1.0608 - social_signal_output_accuracy: 0.6025 - social_signal_output_loss: 0.8920 - val_activity_output_accuracy: 0.9541 - val_activity_output_loss: 0.1408 - val_loss: 0.9881 - val_social_signal_output_accuracy: 0.6137 - val_social_signal_output_loss: 0.8472\n",
      "Epoch 7/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9497 - activity_output_loss: 0.1579 - loss: 1.0438 - social_signal_output_accuracy: 0.6053 - social_signal_output_loss: 0.8859 - val_activity_output_accuracy: 0.9598 - val_activity_output_loss: 0.1271 - val_loss: 0.9731 - val_social_signal_output_accuracy: 0.6159 - val_social_signal_output_loss: 0.8456\n",
      "Epoch 8/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9506 - activity_output_loss: 0.1470 - loss: 1.0075 - social_signal_output_accuracy: 0.6088 - social_signal_output_loss: 0.8605 - val_activity_output_accuracy: 0.9605 - val_activity_output_loss: 0.1178 - val_loss: 0.9433 - val_social_signal_output_accuracy: 0.6187 - val_social_signal_output_loss: 0.8251\n",
      "Epoch 9/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9574 - activity_output_loss: 0.1368 - loss: 0.9942 - social_signal_output_accuracy: 0.6118 - social_signal_output_loss: 0.8574 - val_activity_output_accuracy: 0.9643 - val_activity_output_loss: 0.1127 - val_loss: 0.9493 - val_social_signal_output_accuracy: 0.6138 - val_social_signal_output_loss: 0.8363\n",
      "Epoch 10/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9578 - activity_output_loss: 0.1275 - loss: 0.9752 - social_signal_output_accuracy: 0.6163 - social_signal_output_loss: 0.8477 - val_activity_output_accuracy: 0.9677 - val_activity_output_loss: 0.0987 - val_loss: 0.9214 - val_social_signal_output_accuracy: 0.6230 - val_social_signal_output_loss: 0.8225\n",
      "Epoch 11/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9603 - activity_output_loss: 0.1203 - loss: 0.9574 - social_signal_output_accuracy: 0.6168 - social_signal_output_loss: 0.8372 - val_activity_output_accuracy: 0.9660 - val_activity_output_loss: 0.1077 - val_loss: 0.8995 - val_social_signal_output_accuracy: 0.6186 - val_social_signal_output_loss: 0.7914\n",
      "Epoch 12/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9644 - activity_output_loss: 0.1105 - loss: 0.9468 - social_signal_output_accuracy: 0.6140 - social_signal_output_loss: 0.8363 - val_activity_output_accuracy: 0.9698 - val_activity_output_loss: 0.0927 - val_loss: 0.8704 - val_social_signal_output_accuracy: 0.6326 - val_social_signal_output_loss: 0.7774\n",
      "Epoch 13/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9675 - activity_output_loss: 0.1028 - loss: 0.9290 - social_signal_output_accuracy: 0.6181 - social_signal_output_loss: 0.8263 - val_activity_output_accuracy: 0.9646 - val_activity_output_loss: 0.1111 - val_loss: 0.9297 - val_social_signal_output_accuracy: 0.6200 - val_social_signal_output_loss: 0.8183\n",
      "Epoch 14/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9661 - activity_output_loss: 0.1052 - loss: 0.9240 - social_signal_output_accuracy: 0.6199 - social_signal_output_loss: 0.8188 - val_activity_output_accuracy: 0.9659 - val_activity_output_loss: 0.1071 - val_loss: 0.9045 - val_social_signal_output_accuracy: 0.6359 - val_social_signal_output_loss: 0.7973\n",
      "Epoch 15/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9711 - activity_output_loss: 0.0974 - loss: 0.9113 - social_signal_output_accuracy: 0.6250 - social_signal_output_loss: 0.8138 - val_activity_output_accuracy: 0.9689 - val_activity_output_loss: 0.0989 - val_loss: 0.8828 - val_social_signal_output_accuracy: 0.6335 - val_social_signal_output_loss: 0.7836\n",
      "Epoch 16/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9711 - activity_output_loss: 0.0900 - loss: 0.8967 - social_signal_output_accuracy: 0.6321 - social_signal_output_loss: 0.8067 - val_activity_output_accuracy: 0.9670 - val_activity_output_loss: 0.1038 - val_loss: 0.8757 - val_social_signal_output_accuracy: 0.6412 - val_social_signal_output_loss: 0.7716\n",
      "Epoch 17/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9707 - activity_output_loss: 0.0879 - loss: 0.8762 - social_signal_output_accuracy: 0.6355 - social_signal_output_loss: 0.7883 - val_activity_output_accuracy: 0.9713 - val_activity_output_loss: 0.0879 - val_loss: 0.8413 - val_social_signal_output_accuracy: 0.6453 - val_social_signal_output_loss: 0.7531\n",
      "Epoch 18/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9741 - activity_output_loss: 0.0799 - loss: 0.8568 - social_signal_output_accuracy: 0.6412 - social_signal_output_loss: 0.7770 - val_activity_output_accuracy: 0.9732 - val_activity_output_loss: 0.0860 - val_loss: 0.8396 - val_social_signal_output_accuracy: 0.6537 - val_social_signal_output_loss: 0.7534\n",
      "Epoch 19/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9738 - activity_output_loss: 0.0803 - loss: 0.8488 - social_signal_output_accuracy: 0.6439 - social_signal_output_loss: 0.7685 - val_activity_output_accuracy: 0.9752 - val_activity_output_loss: 0.0839 - val_loss: 0.8431 - val_social_signal_output_accuracy: 0.6611 - val_social_signal_output_loss: 0.7589\n",
      "Epoch 20/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9765 - activity_output_loss: 0.0755 - loss: 0.8410 - social_signal_output_accuracy: 0.6492 - social_signal_output_loss: 0.7655 - val_activity_output_accuracy: 0.9735 - val_activity_output_loss: 0.0861 - val_loss: 0.8286 - val_social_signal_output_accuracy: 0.6705 - val_social_signal_output_loss: 0.7423\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Completed fold 2\n",
      "Training fold 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - activity_output_accuracy: 0.8634 - activity_output_loss: 0.5559 - loss: 1.7616 - social_signal_output_accuracy: 0.5222 - social_signal_output_loss: 1.2057 - val_activity_output_accuracy: 0.9046 - val_activity_output_loss: 0.2981 - val_loss: 1.3602 - val_social_signal_output_accuracy: 0.5706 - val_social_signal_output_loss: 1.0614\n",
      "Epoch 2/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9030 - activity_output_loss: 0.3005 - loss: 1.3276 - social_signal_output_accuracy: 0.5794 - social_signal_output_loss: 1.0271 - val_activity_output_accuracy: 0.9273 - val_activity_output_loss: 0.2183 - val_loss: 1.1506 - val_social_signal_output_accuracy: 0.6067 - val_social_signal_output_loss: 0.9317\n",
      "Epoch 3/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9237 - activity_output_loss: 0.2418 - loss: 1.1866 - social_signal_output_accuracy: 0.5982 - social_signal_output_loss: 0.9448 - val_activity_output_accuracy: 0.9453 - val_activity_output_loss: 0.1715 - val_loss: 1.0633 - val_social_signal_output_accuracy: 0.6131 - val_social_signal_output_loss: 0.8911\n",
      "Epoch 4/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9377 - activity_output_loss: 0.2024 - loss: 1.1188 - social_signal_output_accuracy: 0.6006 - social_signal_output_loss: 0.9164 - val_activity_output_accuracy: 0.9500 - val_activity_output_loss: 0.1580 - val_loss: 1.0298 - val_social_signal_output_accuracy: 0.6105 - val_social_signal_output_loss: 0.8712\n",
      "Epoch 5/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9447 - activity_output_loss: 0.1815 - loss: 1.0845 - social_signal_output_accuracy: 0.6022 - social_signal_output_loss: 0.9030 - val_activity_output_accuracy: 0.9548 - val_activity_output_loss: 0.1412 - val_loss: 0.9931 - val_social_signal_output_accuracy: 0.6162 - val_social_signal_output_loss: 0.8514\n",
      "Epoch 6/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9480 - activity_output_loss: 0.1632 - loss: 1.0463 - social_signal_output_accuracy: 0.6057 - social_signal_output_loss: 0.8832 - val_activity_output_accuracy: 0.9571 - val_activity_output_loss: 0.1316 - val_loss: 0.9907 - val_social_signal_output_accuracy: 0.6196 - val_social_signal_output_loss: 0.8585\n",
      "Epoch 7/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9495 - activity_output_loss: 0.1548 - loss: 1.0225 - social_signal_output_accuracy: 0.6133 - social_signal_output_loss: 0.8677 - val_activity_output_accuracy: 0.9618 - val_activity_output_loss: 0.1217 - val_loss: 0.9795 - val_social_signal_output_accuracy: 0.6107 - val_social_signal_output_loss: 0.8572\n",
      "Epoch 8/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9558 - activity_output_loss: 0.1391 - loss: 0.9891 - social_signal_output_accuracy: 0.6141 - social_signal_output_loss: 0.8499 - val_activity_output_accuracy: 0.9599 - val_activity_output_loss: 0.1227 - val_loss: 0.9475 - val_social_signal_output_accuracy: 0.6197 - val_social_signal_output_loss: 0.8242\n",
      "Epoch 9/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9593 - activity_output_loss: 0.1292 - loss: 0.9678 - social_signal_output_accuracy: 0.6232 - social_signal_output_loss: 0.8386 - val_activity_output_accuracy: 0.9640 - val_activity_output_loss: 0.1071 - val_loss: 0.9156 - val_social_signal_output_accuracy: 0.6248 - val_social_signal_output_loss: 0.8081\n",
      "Epoch 10/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9617 - activity_output_loss: 0.1264 - loss: 0.9563 - social_signal_output_accuracy: 0.6224 - social_signal_output_loss: 0.8299 - val_activity_output_accuracy: 0.9652 - val_activity_output_loss: 0.1101 - val_loss: 0.9009 - val_social_signal_output_accuracy: 0.6285 - val_social_signal_output_loss: 0.7904\n",
      "Epoch 11/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9640 - activity_output_loss: 0.1136 - loss: 0.9319 - social_signal_output_accuracy: 0.6275 - social_signal_output_loss: 0.8183 - val_activity_output_accuracy: 0.9696 - val_activity_output_loss: 0.0959 - val_loss: 0.8625 - val_social_signal_output_accuracy: 0.6416 - val_social_signal_output_loss: 0.7660\n",
      "Epoch 12/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9678 - activity_output_loss: 0.1043 - loss: 0.9088 - social_signal_output_accuracy: 0.6275 - social_signal_output_loss: 0.8045 - val_activity_output_accuracy: 0.9682 - val_activity_output_loss: 0.0994 - val_loss: 0.8562 - val_social_signal_output_accuracy: 0.6434 - val_social_signal_output_loss: 0.7563\n",
      "Epoch 13/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9676 - activity_output_loss: 0.1017 - loss: 0.8832 - social_signal_output_accuracy: 0.6390 - social_signal_output_loss: 0.7815 - val_activity_output_accuracy: 0.9704 - val_activity_output_loss: 0.0995 - val_loss: 0.8386 - val_social_signal_output_accuracy: 0.6615 - val_social_signal_output_loss: 0.7386\n",
      "Epoch 14/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9704 - activity_output_loss: 0.0961 - loss: 0.8735 - social_signal_output_accuracy: 0.6430 - social_signal_output_loss: 0.7774 - val_activity_output_accuracy: 0.9715 - val_activity_output_loss: 0.0956 - val_loss: 0.8289 - val_social_signal_output_accuracy: 0.6611 - val_social_signal_output_loss: 0.7329\n",
      "Epoch 15/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9719 - activity_output_loss: 0.0884 - loss: 0.8469 - social_signal_output_accuracy: 0.6484 - social_signal_output_loss: 0.7584 - val_activity_output_accuracy: 0.9717 - val_activity_output_loss: 0.0899 - val_loss: 0.8186 - val_social_signal_output_accuracy: 0.6726 - val_social_signal_output_loss: 0.7281\n",
      "Epoch 16/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9738 - activity_output_loss: 0.0856 - loss: 0.8435 - social_signal_output_accuracy: 0.6517 - social_signal_output_loss: 0.7579 - val_activity_output_accuracy: 0.9727 - val_activity_output_loss: 0.1038 - val_loss: 0.8470 - val_social_signal_output_accuracy: 0.6707 - val_social_signal_output_loss: 0.7427\n",
      "Epoch 17/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9727 - activity_output_loss: 0.0839 - loss: 0.8258 - social_signal_output_accuracy: 0.6583 - social_signal_output_loss: 0.7419 - val_activity_output_accuracy: 0.9720 - val_activity_output_loss: 0.0937 - val_loss: 0.8022 - val_social_signal_output_accuracy: 0.6807 - val_social_signal_output_loss: 0.7079\n",
      "Epoch 18/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9750 - activity_output_loss: 0.0824 - loss: 0.8107 - social_signal_output_accuracy: 0.6686 - social_signal_output_loss: 0.7282 - val_activity_output_accuracy: 0.9717 - val_activity_output_loss: 0.0953 - val_loss: 0.7991 - val_social_signal_output_accuracy: 0.6879 - val_social_signal_output_loss: 0.7036\n",
      "Epoch 19/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9762 - activity_output_loss: 0.0798 - loss: 0.8050 - social_signal_output_accuracy: 0.6665 - social_signal_output_loss: 0.7252 - val_activity_output_accuracy: 0.9745 - val_activity_output_loss: 0.0885 - val_loss: 0.7701 - val_social_signal_output_accuracy: 0.6921 - val_social_signal_output_loss: 0.6813\n",
      "Epoch 20/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9773 - activity_output_loss: 0.0726 - loss: 0.7879 - social_signal_output_accuracy: 0.6735 - social_signal_output_loss: 0.7153 - val_activity_output_accuracy: 0.9752 - val_activity_output_loss: 0.0881 - val_loss: 0.7788 - val_social_signal_output_accuracy: 0.6824 - val_social_signal_output_loss: 0.6901\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Completed fold 3\n",
      "Training fold 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_8[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_9[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.8607 - activity_output_loss: 0.5569 - loss: 1.7702 - social_signal_output_accuracy: 0.5091 - social_signal_output_loss: 1.2133 - val_activity_output_accuracy: 0.9165 - val_activity_output_loss: 0.2573 - val_loss: 1.2923 - val_social_signal_output_accuracy: 0.5785 - val_social_signal_output_loss: 1.0348\n",
      "Epoch 2/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9056 - activity_output_loss: 0.2937 - loss: 1.3146 - social_signal_output_accuracy: 0.5858 - social_signal_output_loss: 1.0209 - val_activity_output_accuracy: 0.9387 - val_activity_output_loss: 0.2014 - val_loss: 1.1451 - val_social_signal_output_accuracy: 0.5953 - val_social_signal_output_loss: 0.9434\n",
      "Epoch 3/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9283 - activity_output_loss: 0.2304 - loss: 1.1708 - social_signal_output_accuracy: 0.5969 - social_signal_output_loss: 0.9405 - val_activity_output_accuracy: 0.9504 - val_activity_output_loss: 0.1678 - val_loss: 1.0830 - val_social_signal_output_accuracy: 0.6076 - val_social_signal_output_loss: 0.9147\n",
      "Epoch 4/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9399 - activity_output_loss: 0.1945 - loss: 1.1057 - social_signal_output_accuracy: 0.6000 - social_signal_output_loss: 0.9112 - val_activity_output_accuracy: 0.9571 - val_activity_output_loss: 0.1499 - val_loss: 1.0173 - val_social_signal_output_accuracy: 0.6165 - val_social_signal_output_loss: 0.8669\n",
      "Epoch 5/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9465 - activity_output_loss: 0.1682 - loss: 1.0639 - social_signal_output_accuracy: 0.6011 - social_signal_output_loss: 0.8956 - val_activity_output_accuracy: 0.9598 - val_activity_output_loss: 0.1386 - val_loss: 0.9783 - val_social_signal_output_accuracy: 0.6131 - val_social_signal_output_loss: 0.8392\n",
      "Epoch 6/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9507 - activity_output_loss: 0.1530 - loss: 1.0154 - social_signal_output_accuracy: 0.6115 - social_signal_output_loss: 0.8625 - val_activity_output_accuracy: 0.9607 - val_activity_output_loss: 0.1329 - val_loss: 0.9764 - val_social_signal_output_accuracy: 0.6167 - val_social_signal_output_loss: 0.8430\n",
      "Epoch 7/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9557 - activity_output_loss: 0.1392 - loss: 1.0015 - social_signal_output_accuracy: 0.6092 - social_signal_output_loss: 0.8622 - val_activity_output_accuracy: 0.9636 - val_activity_output_loss: 0.1268 - val_loss: 0.9346 - val_social_signal_output_accuracy: 0.6206 - val_social_signal_output_loss: 0.8075\n",
      "Epoch 8/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9563 - activity_output_loss: 0.1384 - loss: 0.9739 - social_signal_output_accuracy: 0.6234 - social_signal_output_loss: 0.8355 - val_activity_output_accuracy: 0.9658 - val_activity_output_loss: 0.1240 - val_loss: 0.9415 - val_social_signal_output_accuracy: 0.6262 - val_social_signal_output_loss: 0.8169\n",
      "Epoch 9/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9617 - activity_output_loss: 0.1215 - loss: 0.9658 - social_signal_output_accuracy: 0.6171 - social_signal_output_loss: 0.8443 - val_activity_output_accuracy: 0.9648 - val_activity_output_loss: 0.1254 - val_loss: 0.9493 - val_social_signal_output_accuracy: 0.6238 - val_social_signal_output_loss: 0.8236\n",
      "Epoch 10/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9639 - activity_output_loss: 0.1110 - loss: 0.9484 - social_signal_output_accuracy: 0.6213 - social_signal_output_loss: 0.8373 - val_activity_output_accuracy: 0.9704 - val_activity_output_loss: 0.1055 - val_loss: 0.9110 - val_social_signal_output_accuracy: 0.6269 - val_social_signal_output_loss: 0.8049\n",
      "Epoch 11/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9677 - activity_output_loss: 0.1046 - loss: 0.9233 - social_signal_output_accuracy: 0.6288 - social_signal_output_loss: 0.8187 - val_activity_output_accuracy: 0.9653 - val_activity_output_loss: 0.1275 - val_loss: 0.9301 - val_social_signal_output_accuracy: 0.6340 - val_social_signal_output_loss: 0.8020\n",
      "Epoch 12/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - activity_output_accuracy: 0.9685 - activity_output_loss: 0.1015 - loss: 0.9084 - social_signal_output_accuracy: 0.6341 - social_signal_output_loss: 0.8068 - val_activity_output_accuracy: 0.9715 - val_activity_output_loss: 0.1042 - val_loss: 0.8632 - val_social_signal_output_accuracy: 0.6408 - val_social_signal_output_loss: 0.7584\n",
      "Epoch 13/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9711 - activity_output_loss: 0.0927 - loss: 0.8865 - social_signal_output_accuracy: 0.6354 - social_signal_output_loss: 0.7938 - val_activity_output_accuracy: 0.9712 - val_activity_output_loss: 0.1048 - val_loss: 0.8720 - val_social_signal_output_accuracy: 0.6427 - val_social_signal_output_loss: 0.7666\n",
      "Epoch 14/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9717 - activity_output_loss: 0.0905 - loss: 0.8773 - social_signal_output_accuracy: 0.6408 - social_signal_output_loss: 0.7868 - val_activity_output_accuracy: 0.9706 - val_activity_output_loss: 0.1079 - val_loss: 0.8740 - val_social_signal_output_accuracy: 0.6502 - val_social_signal_output_loss: 0.7655\n",
      "Epoch 15/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9755 - activity_output_loss: 0.0819 - loss: 0.8671 - social_signal_output_accuracy: 0.6414 - social_signal_output_loss: 0.7851 - val_activity_output_accuracy: 0.9733 - val_activity_output_loss: 0.1000 - val_loss: 0.8345 - val_social_signal_output_accuracy: 0.6632 - val_social_signal_output_loss: 0.7340\n",
      "Epoch 16/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9748 - activity_output_loss: 0.0810 - loss: 0.8514 - social_signal_output_accuracy: 0.6488 - social_signal_output_loss: 0.7704 - val_activity_output_accuracy: 0.9734 - val_activity_output_loss: 0.0980 - val_loss: 0.8656 - val_social_signal_output_accuracy: 0.6426 - val_social_signal_output_loss: 0.7670\n",
      "Epoch 17/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9767 - activity_output_loss: 0.0748 - loss: 0.8368 - social_signal_output_accuracy: 0.6551 - social_signal_output_loss: 0.7620 - val_activity_output_accuracy: 0.9747 - val_activity_output_loss: 0.1053 - val_loss: 0.8512 - val_social_signal_output_accuracy: 0.6501 - val_social_signal_output_loss: 0.7455\n",
      "Epoch 18/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9771 - activity_output_loss: 0.0779 - loss: 0.8373 - social_signal_output_accuracy: 0.6547 - social_signal_output_loss: 0.7594 - val_activity_output_accuracy: 0.9746 - val_activity_output_loss: 0.1033 - val_loss: 0.8596 - val_social_signal_output_accuracy: 0.6552 - val_social_signal_output_loss: 0.7561\n",
      "Epoch 19/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9786 - activity_output_loss: 0.0712 - loss: 0.8223 - social_signal_output_accuracy: 0.6600 - social_signal_output_loss: 0.7510 - val_activity_output_accuracy: 0.9765 - val_activity_output_loss: 0.1049 - val_loss: 0.8154 - val_social_signal_output_accuracy: 0.6658 - val_social_signal_output_loss: 0.7099\n",
      "Epoch 20/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - activity_output_accuracy: 0.9810 - activity_output_loss: 0.0648 - loss: 0.8094 - social_signal_output_accuracy: 0.6623 - social_signal_output_loss: 0.7446 - val_activity_output_accuracy: 0.9758 - val_activity_output_loss: 0.1021 - val_loss: 0.8481 - val_social_signal_output_accuracy: 0.6512 - val_social_signal_output_loss: 0.7454\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Completed fold 4\n",
      "Training fold 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_10… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_11… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m640\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_10… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_11… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m180,352\u001b[0m │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ social_signal_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,631</span> (811.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,631\u001b[0m (811.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - activity_output_accuracy: 0.8630 - activity_output_loss: 0.5369 - loss: 1.7344 - social_signal_output_accuracy: 0.5158 - social_signal_output_loss: 1.1975 - val_activity_output_accuracy: 0.9142 - val_activity_output_loss: 0.2605 - val_loss: 1.3060 - val_social_signal_output_accuracy: 0.5545 - val_social_signal_output_loss: 1.0450\n",
      "Epoch 2/20\n",
      "\u001b[1m1215/1215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - activity_output_accuracy: 0.9152 - activity_output_loss: 0.2724 - loss: 1.2678 - social_signal_output_accuracy: 0.5885 - social_signal_output_loss: 0.9955 - val_activity_output_accuracy: 0.9335 - val_activity_output_loss: 0.2139 - val_loss: 1.1350 - val_social_signal_output_accuracy: 0.5950 - val_social_signal_output_loss: 0.9206\n",
      "Epoch 3/20\n",
      "\u001b[1m 244/1215\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - activity_output_accuracy: 0.9319 - activity_output_loss: 0.2143 - loss: 1.1412 - social_signal_output_accuracy: 0.5987 - social_signal_output_loss: 0.9269"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38104\\479787883.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Build and compile the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_1d_cnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_activity_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_social_signal_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Train the model on this fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mX_train_fold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[1;34m'activity_output'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_activity_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'social_signal_output'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_social_signal_fold\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_init_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# One-indexed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\utils\\progbar.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33mf\"\u001b[0m\u001b[1;33m - \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                     avg = backend.convert_to_numpy(\n\u001b[1;32m--> 163\u001b[1;33m                         backend.numpy.mean(\n\u001b[0m\u001b[0;32m    164\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, axis, keepdims)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"int\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mori_dtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mori_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"bool\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mresult_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mresult_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mori_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m     output = tf.reduce_mean(\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2548\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2549\u001b[0m   return _may_reduce_to_scalar(\n\u001b[0;32m   2550\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2551\u001b[0m       gen_math_ops.mean(\n\u001b[1;32m-> 2552\u001b[1;33m           \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2553\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   2052\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx_rank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m       \u001b[1;31m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[0;32m   2023\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2024\u001b[0m     \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2025\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2027\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(start, limit, delta, name)\u001b[0m\n\u001b[0;32m   8836\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Range\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8837\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8838\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8839\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8840\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8841\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8842\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8843\u001b[0m       return _range_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialise lists to store the accuracy of each fold\n",
    "activity_accuracy = []\n",
    "social_signal_accuracy = []\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    print(f\"Training fold {fold_no}\")\n",
    "\n",
    "    # Split the data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_activity_fold, y_val_activity_fold = y_train_activity_one_hot[train_index], y_train_activity_one_hot[val_index]\n",
    "    y_train_social_signal_fold, y_val_social_signal_fold = y_train_social_signal_one_hot[train_index], y_train_social_signal_one_hot[val_index]\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes)\n",
    "\n",
    "    # Train the model on this fold\n",
    "    history = model.fit(\n",
    "        X_train_fold,\n",
    "        {'activity_output': y_train_activity_fold, 'social_signal_output': y_train_social_signal_fold},\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_fold, {'activity_output': y_val_activity_fold, 'social_signal_output': y_val_social_signal_fold})\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred_probs = model.predict(X_val_fold)\n",
    "    y_pred_probs_activity = np.argmax(y_pred_probs[0], axis = 1)\n",
    "    y_pred_probs_social_signal = np.argmax(y_pred_probs[1], axis = 1)\n",
    "\n",
    "    y_true_activity = np.argmax(y_val_activity_fold, axis = 1)\n",
    "    y_true_social_signal = np.argmax(y_val_social_signal_fold, axis = 1)\n",
    "\n",
    "    # Generate the classification report for activity and social signal labels\n",
    "    report_activity = classification_report(y_true_activity, y_pred_probs_activity, output_dict=True)\n",
    "    report_social_signal = classification_report(y_true_social_signal, y_pred_probs_social_signal, output_dict=True)\n",
    "\n",
    "    # Append the reports to the lists for averaging later\n",
    "    activity_accuracy.append(report_activity['accuracy'])\n",
    "    social_signal_accuracy.append(report_social_signal['accuracy'])\n",
    "\n",
    "    print(f\"Completed fold {fold_no}\")\n",
    "    fold_no += 1\n",
    "\n",
    "average_activity_accuracy = np.mean(activity_accuracy)\n",
    "average_social_signal_accuracy = np.mean(social_signal_accuracy)\n",
    "\n",
    "print(f\"Average Activity Accuracy: {average_activity_accuracy:.4f}\")\n",
    "print(f\"Average Social Signal Accuracy: {average_social_signal_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHNzGOHDtnQ4"
   },
   "source": [
    "# Exporting your model to TFLite\n",
    "\n",
    "You can use the TFLiteConverter class provided by TensorFlow to convert your trained model into the TensorFlow Lite format. We export models to TensorFlow Lite (TFLite) for several reasons, primarily because TFLite is designed for deployment on edge devices, such as mobile phones, embedded systems, IoT devices, and microcontrollers, where computational resources and power are limited. This is necessary as you will be running your ML models on your Android devices to perform live classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_QKoJtmufDa",
    "outputId": "48d281ab-4ed3-4ee1-fd47-30f7f4c10b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpcjr4lwin\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpcjr4lwin\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpcjr4lwin'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  List[TensorSpec(shape=(None, 11), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  1387511079824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511079632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511082128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511082320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511080976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511082896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511083472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511085584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511083088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1387511084048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model successfully exported to model.tflite\n"
     ]
    }
   ],
   "source": [
    "# Convert the trained Keras model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # model is your trained Keras model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model to a .tflite file\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model successfully exported to model.tflite\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
