{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzd9Z9OZxNvd"
   },
   "source": [
    "# **Machine Learning Model**\n",
    "\n",
    "This notebook implements a convolutional neural network to recognise different physical activities from Respeck sensor data. The dataset includes multiple 30-second recordings of various physical activities (e.g., ascending stairs, shuffle walking, sitting-standing) stored in separate CSV files for each activity.\n",
    "\n",
    "This model will be deployed inside the Android app for live classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXyHZD1A0X7J"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s2B8Hymdj1Sg"
   },
   "outputs": [],
   "source": [
    "# Importing libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icbrBf1Kl6vp"
   },
   "source": [
    "# Reading Files\n",
    "Reading files from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pTsJd33Kl44J"
   },
   "outputs": [],
   "source": [
    "# Path to Respeck data\n",
    "your_dataset_path = \"./PDIoT2324/Respeck/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOTe3o9Il4ST"
   },
   "source": [
    "This line uses the glob module to find all file paths that match a specified pattern. The 'glob.glob()' function returns a list of file paths that match the given pattern. `your_dataset_path` should be the directory where your dataset files are located.\n",
    "\n",
    "The `*` is a wildcard character that matches any string of characters,  so this pattern retrieves all folders in the 'your_dataset_path' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4izGxKkllz6",
    "outputId": "49f7031e-36ae-454a-a8dc-4a7e92243315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PDIoT2324/Respeck\\\\s100_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_hyperventilating.csv',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(your_dataset_path + \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities and Social Signals Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activities and social signals with corresponding labels\n",
    "# Each key is the name of the physical activity, and the corresponding value is the numeric label\n",
    "# These labels will be used as the target variable for classification\n",
    "activities_dict = {\n",
    "    'ascending': 0,\n",
    "    'shuffleWalking': 1,\n",
    "    'sittingStanding': 2,\n",
    "    'miscMovement': 3,\n",
    "    'normalWalking': 4,\n",
    "    'lyingBack': 5,\n",
    "    'lyingLeft': 6,\n",
    "    'lyingRight': 7,\n",
    "    'lyingStomach': 8,\n",
    "    'descending': 9,\n",
    "    'running': 10\n",
    "}\n",
    "\n",
    "social_signals_dict = {\n",
    "    'breathingNormal': 0,\n",
    "    'coughing': 1,\n",
    "    'hyperventilating': 2,\n",
    "    'other': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7eNuiHKmBuT"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zdg12YooOJF"
   },
   "source": [
    "## Load list of files in an activity folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b_ZtuAb64ZsD"
   },
   "outputs": [],
   "source": [
    "def load_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load all CSV files from a folder, extract activity and social signal information,\n",
    "    and return a list of file paths along with combined labels and file information.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing CSV files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - list: A list of file paths for all CSV files in the folder.\n",
    "        - list: A list of combined labels (activity and social signal) for each file.\n",
    "        - dict: A dictionary containing file information with activity and social signal labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise an empty list to store the full file paths of the CSV files\n",
    "    file_paths = []\n",
    "\n",
    "    # Initialise an empty dictionary to store the filenames and the activity and social signal labels\n",
    "    file_info = {}\n",
    "\n",
    "    # Initialise an empty list to store the combined labels of the activity and social signal to be used in stratified split of data\n",
    "    # Stratified split of data ensures that each activity-social signal combination is proportionally represented in the training and testing data\n",
    "    combined_labels = []\n",
    "\n",
    "    # Loop through all the files in the given folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        \n",
    "        # Check if the file has a .csv extension (ignores other files)\n",
    "        if file_name.endswith('.csv'):\n",
    "\n",
    "            # Inialise an empty dictionary for each file to store the activity and social signal labels\n",
    "            file_info[file_name] = {}\n",
    "\n",
    "            # Split the file name by underscores to extract activity and social signal information\n",
    "            parts = file_name.split(\"_\")\n",
    "            \n",
    "            # Extract the activity from the file name\n",
    "            activity = parts[2]\n",
    "\n",
    "            # Add activity label to the file_info dictionary\n",
    "            if activity == \"sitting\" or activity == \"standing\":\n",
    "                file_info[file_name]['activity_label'] = activities_dict[\"sittingStanding\"]\n",
    "            else:\n",
    "                file_info[file_name]['activity_label'] = activities_dict[activity]\n",
    "            \n",
    "            # Extract the social signal from the file name, without the .csv extension\n",
    "            social_signal = parts[3].split(\".\")[0]\n",
    "\n",
    "            # Add social signal label to the file_info dictionary\n",
    "            if social_signal == \"laughing\" or social_signal == \"eating\" or social_signal == \"talking\" or social_signal == \"singing\":\n",
    "                file_info[file_name]['social_signal_label'] = social_signals_dict[\"other\"]\n",
    "            else:\n",
    "                file_info[file_name]['social_signal_label'] = social_signals_dict[social_signal]\n",
    "            \n",
    "            # Combine the activity and social signal to create a unique label\n",
    "            combined_label = activity + \"_\" + social_signal\n",
    "\n",
    "            # Append the combined label to the combined_labels list\n",
    "            combined_labels.append(combined_label)\n",
    "\n",
    "            # Construct the full file path by joining the folder path and the file name'\n",
    "            full_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Append the full file path to the file_paths list\n",
    "            file_paths.append(full_file_path)\n",
    "\n",
    "    # Return the complete list of CSV file paths\n",
    "    return file_paths, combined_labels, file_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUGBeBBn_L8"
   },
   "source": [
    "## Train and test set split from list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2SzHoQz2NH3v"
   },
   "outputs": [],
   "source": [
    "def split_files(file_list, combined_labels, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the list of file paths into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): A list of file paths for all CSV files.\n",
    "    combined_labels (list): A list of combined labels (activity and social signal) for each file.\n",
    "    test_size (float, optional): The proportion of the dataset to include in the test split. Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - list: Training file paths.\n",
    "        - list: Testing file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the file list into training and test sets using train_test_split from scikit-learn\n",
    "    # test_size defines the proportion of the data to use as the test set (default is 20%)\n",
    "    # shuffle=True ensures that the files are shuffled randomly before splitting\n",
    "    # stratify is used to ensure that the proportion of each class is the same in both the training and testing sets\n",
    "    # Separate files for each social signal class\n",
    "    breathing_normal_files = [file for file, label in zip(file_list, combined_labels) if 'breathingNormal' in label]\n",
    "    coughing_files = [file for file, label in zip(file_list, combined_labels) if 'coughing' in label]\n",
    "    hyperventilating_files = [file for file, label in zip(file_list, combined_labels) if 'hyperventilating' in label]\n",
    "    other_files = [file for file, label in zip(file_list, combined_labels) if 'laughing' in label or 'eating' in label or 'talking' in label or 'singing' in label]\n",
    "\n",
    "    # Determine the target sample size for each class (e.g., the maximum class size to upsample to)\n",
    "    target_samples = max(len(breathing_normal_files), len(coughing_files), len(hyperventilating_files), len(other_files))\n",
    "\n",
    "    # Upsample each class to have the same number of samples\n",
    "    breathing_normal_files = resample(breathing_normal_files, replace=True, n_samples=target_samples, random_state=42)\n",
    "    coughing_files = resample(coughing_files, replace=True, n_samples=target_samples, random_state=42)\n",
    "    hyperventilating_files = resample(hyperventilating_files, replace=True, n_samples=target_samples, random_state=42)\n",
    "    other_files = resample(other_files, replace=True, n_samples=target_samples, random_state=42)\n",
    "\n",
    "    # Combine the balanced samples\n",
    "    balanced_files = breathing_normal_files + coughing_files + hyperventilating_files + other_files\n",
    "    balanced_labels = (\n",
    "    ['breathingNormal'] * len(breathing_normal_files) +\n",
    "    ['coughing'] * len(coughing_files) +\n",
    "    ['hyperventilating'] * len(hyperventilating_files) +\n",
    "    ['other'] * len(other_files)\n",
    ")\n",
    "\n",
    "    # Now split with stratification\n",
    "    train_files, test_files = train_test_split(\n",
    "        balanced_files, test_size=test_size, stratify=balanced_labels, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    # Return the train and test file lists\n",
    "    return train_files, test_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J7-zQgZzP19"
   },
   "source": [
    "## Sliding Window\n",
    "\n",
    "In time series Activity Recognition, a sliding window is a commonly used technique to segment continuous sensor data (such as accelerometer readings) into smaller, fixed-length overlapping or non-overlapping time intervals, or windows. Each window contains a sequence of sensor measurements that represent a short period of time, and this segmented data is used to extract features or make predictions about the activity happening within that window.\n",
    "\n",
    "### Key Concepts of a Sliding Window\n",
    "1.   **Window Size:** This refers to the length of each segment or window, typically defined in terms of the number of time steps or the duration (e.g., 2 seconds). The window size should be chosen carefully to capture enough information about the activity without making the window too large.\n",
    "2.   **Step Size:** The step size determines how far the window moves forward after each step. If the step size is smaller than the window size, the windows will overlap. For example, if the window size is 5 seconds and the step size is 2 seconds, there will be a 3-second overlap between consecutive windows. Overlapping windows provide more data for analysis and can help smooth out predictions by capturing transitional activities.\n",
    "3.   **Non-Overlapping Windows:** If the step size is equal to the window size, the windows do not overlap. This method provides distinct segments of data but may miss transitional phases between activities.\n",
    "\n",
    "### Why Sliding Windows for Activity Recognition?\n",
    "\n",
    "* Segmentation of Continuous Data: Activity recognition systems work with continuous streams of sensor data, and the sliding window helps segment these into manageable pieces to classify activities within specific intervals.\n",
    "\n",
    "* Context Capturing: Human activities are often complex and spread across time. By using a sliding window, you can capture context across a short duration, which may include transitions or small fluctuations in the activity (e.g., a person moving from sitting to standing).\n",
    "\n",
    "* Feature Extraction: Within each window, features such as mean, variance, frequency domain features, etc., can be extracted to help classify the activity.\n",
    "\n",
    "* Real-Time Recognition: In real-time systems, the sliding window allows for continuous monitoring and updating of predictions as new data arrives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u3SuHww6MpEx"
   },
   "outputs": [],
   "source": [
    "def load_and_apply_sliding_windows(file_path, window_size, step_size, file_info):\n",
    "    \"\"\"\n",
    "    Load the data from each file, apply sliding windows, and return the windows and labels.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths to CSV files. Each file contains sensor data.\n",
    "    window_size (int): The size of each sliding window (number of time steps).\n",
    "    step_size (int): The step size (stride) between consecutive windows.\n",
    "    file_info (dict): Dictionary containing file information with activity and social signal labels.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - windows (numpy.ndarray): A 3D array of sliding windows, where each window has the shape\n",
    "                                   (num_windows, window_size, num_features).\n",
    "        - activity_labels (numpy.ndarray): A 1D array of activity labels, where each label corresponds to a sliding window.\n",
    "        - social_signal_labels (numpy.ndarray): A 1D array of social signal labels, where each label corresponds to a sliding window.\n",
    "    \"\"\"\n",
    "    # Initialise lists to store sliding windows and their corresponding labels\n",
    "    windows = []\n",
    "    activity_labels = []\n",
    "    social_signal_labels = []\n",
    "    file_number = 0\n",
    "\n",
    "    \n",
    "    # Loop through each file in the provided file path\n",
    "    for file in file_path:\n",
    "\n",
    "        # Extract the activity and social signal labels from the file_info dictionary\n",
    "        activity_label = file_info[os.path.basename(file)]['activity_label']\n",
    "        social_signal_label = file_info[os.path.basename(file)]['social_signal_label']\n",
    "\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        data = pd.read_csv(file)   \n",
    "\n",
    "\n",
    "        # Select the columns containing the necessary sensor data (acceleration readings)\n",
    "        # These columns might vary depending on your dataset's structure\n",
    "        data = data[['accel_x', 'accel_y', 'accel_z']]\n",
    "        \n",
    "        # Convert the DataFrame into a numpy array for faster processing in the sliding window operation\n",
    "        data = data.to_numpy()\n",
    "\n",
    "        \n",
    "        # Get the number of samples (rows) and features (columns) in the data\n",
    "        num_samples, num_features = data.shape\n",
    "        \n",
    "        # Apply sliding windows to the data\n",
    "        # The range function defines the start of each window, moving step_size increments at a time\n",
    "        for i in range(0, num_samples - window_size + 1, step_size):\n",
    "            # Extract a window of size 'window_size' from the current position 'i'\n",
    "            window = data[i:i + window_size, :]\n",
    "\n",
    "            # Append the window to the windows list\n",
    "            windows.append(window)\n",
    "\n",
    "            # Assign the activity label to the window and append it to the activity labels list\n",
    "            activity_labels.append(activity_label)\n",
    "\n",
    "            # Assign the social signal label to the window and append it to the social signal labels list\n",
    "            social_signal_labels.append(social_signal_label)\n",
    "\n",
    "    # Convert the lists of windows and labels into numpy arrays for efficient numerical operations\n",
    "    return np.array(windows), np.array(activity_labels), np.array(social_signal_labels) \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Ku5P4Lm8QA"
   },
   "source": [
    "## Load and Split Train Test for Each Activity Folder\n",
    "\n",
    "This function processes the sensor data for a specific activity, such as 'walking' or 'running', stored in its respective folder. It splits the data into training and testing sets, applies sliding windows, and labels the windows with the corresponding activity. This function can be used repeatedly for each activity to process and prepare data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zBVvTBi7N_fh"
   },
   "outputs": [],
   "source": [
    "def process_activity(dataset_path, window_size=100, step_size=50, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Processes an activity folder by loading the file list, splitting them into\n",
    "    train and test sets, and applying sliding windows to the files.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Base path where the activity folders are located.\n",
    "        window_size (int): Size of the sliding window, i.e., the number of time steps included in each window.\n",
    "                           Default is 50.\n",
    "        step_size (int): Step size for the sliding window, i.e., how far the window moves along the data.\n",
    "                         Default is 20 (no overlap between windows).\n",
    "        test_size (float): Proportion of files to use for testing. Default is 0.2, meaning 20% of files will\n",
    "                           be allocated to the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - train_windows (numpy.ndarray): Sliding windows from the training files.\n",
    "            - train_activity_labels (numpy.ndarray): Corresponding activity labels for the training windows.\n",
    "            - train_social_signal_labels (numpy.ndarray): Corresponding social signal labels for the training windows.\n",
    "            - test_windows (numpy.ndarray): Sliding windows from the test files.\n",
    "            - test_activity_labels (numpy.ndarray): Corresponding activity labels for the test windows.\n",
    "            - test_social_signal_labels (numpy.ndarray): Corresponding social signal labels for the test windows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all CSV file paths for the given activity from the folder\n",
    "    file_paths, combined_labels, file_info = load_files_from_folder(dataset_path)\n",
    "\n",
    "    # Split the file list into training and testing sets\n",
    "    # train_files: files used for training\n",
    "    # test_files: files used for testing\n",
    "    train_files, test_files = split_files(file_paths, combined_labels, test_size=test_size)\n",
    "\n",
    "    # Apply sliding windows to the training files\n",
    "    # The function 'load_and_apply_sliding_windows' returns the sliding windows (segments) and their corresponding activity and social signal labels\n",
    "    train_windows, train_activity_labels, train_social_signal_labels = load_and_apply_sliding_windows(train_files, window_size, step_size, file_info)\n",
    "\n",
    "    # Apply sliding windows to the testing files\n",
    "    test_windows, test_activity_labels, test_social_signal_labels = load_and_apply_sliding_windows(test_files, window_size, step_size, file_info)\n",
    "\n",
    "    # Return the sliding windows and their labels for both training and testing sets\n",
    "    return train_windows, train_activity_labels, train_social_signal_labels, test_windows, test_activity_labels, test_social_signal_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wv1PuOLgUV8"
   },
   "source": [
    "## 1D CNN Model\n",
    "\n",
    "This function, `build_1d_cnn_model`, creates and compiles a 1D Convolutional Neural Network (CNN) for multi-label classification tasks.\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "Input Parameters\n",
    "* `input_shape`: Specifies the shape of the input data. It represents (timesteps, features), where timesteps refer to the length of the time series (e.g., 50 windows), and features represent the number of measurements in each time step (e.g., accelerometer readings).\n",
    "* `num_activity_classes`: The number of output classes for the activity classification problem.\n",
    "* `num_social_signal_classes`: The number of output classes for the social signal classification problem.\n",
    "\n",
    "Returns\n",
    "* The function returns a compiled 1D CNN model with two outputs that is ready to be trained on your data.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Function Breakdown\n",
    "1. **Model Initialization:**\n",
    "    * `inputs = Input(shape=input_shape)`: Initializes the input layer with the specified shape.\n",
    "2. **First Convolutional Layer:**\n",
    "    * `Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)`\n",
    "        * This is the first 1D convolutional layer.\n",
    "        * `filters=64`: The layer applies 64 filters (or kernels) over the input data.\n",
    "        * `kernel_size=3`: Each filter will cover 3 timesteps at a time (a window of 3).\n",
    "        * `activation='relu'`: The Rectified Linear Unit (ReLU) activation function introduces non-linearity and helps the model learn complex patterns.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: This pooling layer reduces the dimensionality of the data by taking the maximum value from each 2-timestep window (`pool_size=2`).\n",
    "3. **Second Convolutional Layer:**\n",
    "    * `Conv1D(filters=128, kernel_size=3, activation='relu')(x)`\n",
    "        * This is the second convolutional layer, similar to the first, but with 128 filters.\n",
    "        * `kernel_size=3` and `activation='relu'` function in the same way as the first Conv1D layer.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: Another pooling layer to downsample the output, further reducing the datas dimensionality.\n",
    "4. **Flattening Layer:**\n",
    "    * `Flatten()(x)`: Converts the 2D output of the convolutional and pooling layers into a 1D vector.\n",
    "5. **Fully Connected Layer:**\n",
    "    * `Dense(128, activation='relu')(x)`: This is a fully connected layer with 128 units/neurons.\n",
    "6. **Dropout Layer:**\n",
    "    * `Dropout(0.5)(x)`: This layer randomly sets 50% of the neurons to zero during training to prevent overfitting.\n",
    "7. **Output Layer for Activity Classification:**\n",
    "    * `Dense(num_activity_classes, activation='softmax', name='activity_output')(x)`: This is the output layer for activity classification with `num_activity_classes` neurons.\n",
    "8. **Output Layer for Social Signal Classification:**\n",
    "    * `Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(x)`: This is the output layer for social signal classification with `num_social_signal_classes` neurons.\n",
    "9. **Model Definition:**\n",
    "    * `model = Model(inputs=inputs, outputs=[activity_output, social_signal_output])`: Defines the model with two outputs.\n",
    "10. **Compiling the Model:**\n",
    "    * `model.compile(optimizer='adam', loss={'activity_output': 'categorical_crossentropy', 'social_signal_output': 'categorical_crossentropy'}, metrics={'activity_output': 'accuracy', 'social_signal_output': 'accuracy'})`\n",
    "        * Optimizer: 'adam': Adam is an optimization algorithm that adjusts the learning rate during training to improve performance.\n",
    "        * Loss: 'categorical_crossentropy': This loss function is used for multi-class classification problems where the target variable is one-hot encoded.\n",
    "        * Metrics: ['accuracy']: The accuracy metric is used to evaluate the models performance during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sCOkh99EOg8t"
   },
   "outputs": [],
   "source": [
    "def build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes):\n",
    "    \"\"\"\n",
    "    Builds and compiles a 1D CNN model for multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (timesteps, features).\n",
    "        num_activity_classes (int): The number of output activity classes.\n",
    "        num_social_signal_classes (int): The number of output social signal classes.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): Compiled 1D CNN model with two outputs.\n",
    "    \"\"\"\n",
    "     # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Shared Conv1D layer\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Separate Conv1D layers for activity and social signal\n",
    "    activity_branch = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    social_signal_branch = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "\n",
    "    # Add LSTM layer for social signal branch\n",
    "    social_signal_branch = MaxPooling1D(pool_size=2)(social_signal_branch)\n",
    "    social_signal_branch = LSTM(64, return_sequences=True)(social_signal_branch)\n",
    "\n",
    "    # Add attention layer for social signal\n",
    "    social_signal_branch = Attention()([social_signal_branch, social_signal_branch])\n",
    "\n",
    "    # Pooling, flatten, and fully connected layers\n",
    "    activity_branch = MaxPooling1D(pool_size=2)(activity_branch)\n",
    "    activity_branch = Flatten()(activity_branch)\n",
    "    activity_branch = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(activity_branch)\n",
    "    activity_branch = Dropout(0.3)(activity_branch)\n",
    "    activity_output = Dense(num_activity_classes, activation='softmax', name='activity_output')(activity_branch)\n",
    "\n",
    "    social_signal_branch = Flatten()(social_signal_branch)\n",
    "    social_signal_branch = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(social_signal_branch)\n",
    "    social_signal_branch = Dropout(0.3)(social_signal_branch)\n",
    "    social_signal_output = Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(social_signal_branch)\n",
    "\n",
    "    # Define the model with two outputs\n",
    "    model = Model(inputs=inputs, outputs=[activity_output, social_signal_output])\n",
    "\n",
    "    # Compile the model with weighted loss\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'activity_output': 'categorical_crossentropy',\n",
    "            'social_signal_output': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'activity_output': 'accuracy',\n",
    "            'social_signal_output': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HurfE6lmOjQT"
   },
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLs1eacYoa_S"
   },
   "source": [
    "## Step 1: Prepare and Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdGR352hph4X"
   },
   "source": [
    "Now the training and testing data will be created by calling the function `process_activity`. The `process_activity` function is used to generate sliding windows and labels for the training and testing sets.\n",
    "* `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
    "* `y_train_activity` and `y_train_social_signal` are 1D arrays of activity and social signal labels for the training set.\n",
    "* `y_test_activity` and `y_test_social_signal` are 1D arrays of activity and social signal labels for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OtpVBr4Fpq_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88697 train windows generated with 88697 activity labels and 88697 social signal labels\n",
      "22179 test windows generated with 22179 activity labels and 22179 social signal labels\n"
     ]
    }
   ],
   "source": [
    "# Generate the sliding windows along with activity and social signal labels for training and testing sets\n",
    "X_train, y_train_activity, y_train_social_signal, X_test, y_test_activity, y_test_social_signal = process_activity(your_dataset_path, test_size=0.2, window_size=50, step_size=50)\n",
    "print(f\"{len(X_train)} train windows generated with {len(y_train_activity)} activity labels and {len(y_train_social_signal)} social signal labels\")\n",
    "print(f\"{len(X_test)} test windows generated with {len(y_test_activity)} activity labels and {len(y_test_social_signal)} social signal labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training and testing sets generated by the `process_activity` function are checked to see that they have the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymA3yh7YFKix",
    "outputId": "3682e518-cfe7-454a-e719-664a4c435732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (88697, 50, 3), y_train_activity shape: (88697,), y_train_social_signal shape: (88697,)\n",
      "X_test shape: (22179, 50, 3), y_test_activity shape: (22179,), y_test_social_signal shape: (22179,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
    "print(f\"X_train shape: {X_train.shape}, y_train_activity shape: {y_train_activity.shape}, y_train_social_signal shape: {y_train_social_signal.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test_activity shape: {y_test_activity.shape}, y_test_social_signal shape: {y_test_social_signal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yQGU1vwIQdz"
   },
   "source": [
    "### One-Hot Encode Labels (for multi-class classification)\n",
    "Since there are more than two classes, the labels must be one-hot encoded, especially as the model will use categorical cross-entropy loss.\n",
    "\n",
    "One-Hot Encoding converts categorical labels into binary vectors (one-hot encoded format). Each class label is represented as a binary vector with 1 for the correct class and 0 for others. This is necessary for training models that use categorical_crossentropy as the loss function, such as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9b2J1EVdHj0U"
   },
   "outputs": [],
   "source": [
    "# Initialise the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the OneHotEncoder on the training activity labels and transform them to one-hot encoded format\n",
    "y_train_activity_one_hot = encoder.fit_transform(y_train_activity.reshape(-1, 1))\n",
    "\n",
    "# Transform the test activity labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_activity_one_hot = encoder.transform(y_test_activity.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Fit the OneHotEncoder on the training social signal labels and transform them to one-hot encoded format\n",
    "y_train_social_signal_one_hot = encoder.fit_transform(y_train_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Transform the test social signal labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_social_signal_one_hot = encoder.transform(y_test_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Explanation:\n",
    "# - y_train_activity_one_hot, y_train_social_signal_one_hot, y_test_activity_one_hot and y_test_social_signal_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
    "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
    "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlnbOVr0rDbV",
    "outputId": "98ddbd62-4d6c-41ba-ac94-00d74a30f3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_activity_one_hot shape: (88697, 11), y_train_social_signal_one_hot shape: (88697, 4), y_test_activity_one_hot shape: (22179, 11), y_test_social_signal_one_hot shape: (22179, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
    "print(f\"y_train_activity_one_hot shape: {y_train_activity_one_hot.shape}, y_train_social_signal_one_hot shape: {y_train_social_signal_one_hot.shape}, y_test_activity_one_hot shape: {y_test_activity_one_hot.shape}, y_test_social_signal_one_hot shape: {y_test_social_signal_one_hot.shape}\")\n",
    "\n",
    "# Explanation of shapes:\n",
    "# - The shape of y_train_activity_one_hot will be (num_samples, num_classes), where:\n",
    "#     - num_samples is the number of training windows.\n",
    "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
    "# - Similarly, y_test_activity_one_hot will have the same number of columns (num_classes) as y_train_activity_one_hot but will have fewer rows (corresponding to the number of test windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEhUxZzzJzzI"
   },
   "source": [
    "## Step 2: Build the 1D-CNN Model\n",
    "Call our `build_1d_cnn_model` function to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "4sDZWZH_KKBD",
    "outputId": "12cc6048-0921-414c-d2d7-b8d5268a8196"
   },
   "outputs": [],
   "source": [
    "# Determine the input shape for the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Determine the number of output classes (num_classes)\n",
    "num_activity_classes = y_train_activity_one_hot.shape[1]\n",
    "num_social_signal_classes = y_train_social_signal_one_hot.shape[1]\n",
    "\n",
    "# Build and compile the model\n",
    "# The function will return a compiled model ready for training\n",
    "model = build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1-SHEmtKM0D"
   },
   "source": [
    "## Step 3: Train and Evaluate the CNN Model\n",
    "\n",
    "Train the 1D CNN model using the training data and validate on the test data. The model will learn to map input sliding windows to their corresponding activity and social signal labels.\n",
    "\n",
    "`model.fit()` is used to train the neural network model. It takes several parameters:\n",
    "* `X_train`: The input training data (sliding windows), with shape (num_samples, window_size, num_features).\n",
    "* `{'activity_output': y_train_activity_one_hot, 'social_signal_output': y_train_social_signal_one_hot}`: The corresponding one-hot encoded labels for the training data, with shape (num_samples, num_classes).\n",
    "* `epochs`: Number of times the entire training dataset is passed through the model. In this case, we are training for 20 epochs, meaning the model will see the entire training set 20 times.\n",
    "* `batch_size`: Number of samples processed before the model's weights are updated. Here, the batch size is set to 32, meaning the model will process 32 samples at a time before updating its parameters.\n",
    "* `validation_data`: This parameter allows us to evaluate the model's performance on the test data after each epoch. It takes the test data and corresponding one-hot encoded test labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model is evaluated on the test set. This is done with  5-Fold Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_accuracy` is the accuracy of the model on the validation data (in this case X_test, y_test_activity_one_hot and y_test_social_signal_one_hot). The `accuracy` is the training accuracy for the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Completed fold 1\n",
      "Training fold 2\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Completed fold 2\n",
      "Training fold 3\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Completed fold 3\n",
      "Training fold 4\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Completed fold 4\n",
      "Training fold 5\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "Completed fold 5\n",
      "Average Activity Accuracy: 0.9751\n",
      "Average Social Signal Accuracy: 0.8131\n"
     ]
    }
   ],
   "source": [
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialise lists to store the accuracy of each fold\n",
    "activity_accuracy = []\n",
    "social_signal_accuracy = []\n",
    "\n",
    "# Initialise lists to store the true and predicted labels for social signals for all folds\n",
    "# These lists will be used to create the confusion matrix for the social signal labels\n",
    "all_y_true_social_signal = []\n",
    "all_y_pred_social_signal = []\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    print(f\"Training fold {fold_no}\")\n",
    "\n",
    "    # Split the data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_activity_fold, y_val_activity_fold = y_train_activity_one_hot[train_index], y_train_activity_one_hot[val_index]\n",
    "    y_train_social_signal_fold, y_val_social_signal_fold = y_train_social_signal_one_hot[train_index], y_train_social_signal_one_hot[val_index]\n",
    "\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes)\n",
    "\n",
    "    # Train the model on this fold\n",
    "    history = model.fit(\n",
    "        X_train_fold,\n",
    "        {'activity_output': y_train_activity_fold, 'social_signal_output': y_train_social_signal_fold},\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_fold, {'activity_output': y_val_activity_fold, 'social_signal_output': y_val_social_signal_fold}),\n",
    "        verbose=0,  # Optional: Set to 0 for silent training\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred_probs = model.predict(X_val_fold)\n",
    "    y_pred_probs_activity = np.argmax(y_pred_probs[0], axis = 1)\n",
    "    y_pred_probs_social_signal = np.argmax(y_pred_probs[1], axis = 1)\n",
    "\n",
    "    y_true_activity = np.argmax(y_val_activity_fold, axis = 1)\n",
    "    y_true_social_signal = np.argmax(y_val_social_signal_fold, axis = 1)\n",
    "\n",
    "    # Generate the classification report for activity and social signal labels\n",
    "    report_activity = classification_report(y_true_activity, y_pred_probs_activity, output_dict=True)\n",
    "    report_social_signal = classification_report(y_true_social_signal, y_pred_probs_social_signal, output_dict=True)\n",
    "\n",
    "    # Collect predictions and true social signal labels for confusion matrix\n",
    "    all_y_true_social_signal.extend(y_true_social_signal)\n",
    "    all_y_pred_social_signal.extend(y_pred_probs_social_signal)\n",
    "\n",
    "    # Append the reports to the lists for averaging later\n",
    "    activity_accuracy.append(report_activity['accuracy'])\n",
    "    social_signal_accuracy.append(report_social_signal['accuracy'])\n",
    "\n",
    "    print(f\"Completed fold {fold_no}\")\n",
    "    fold_no += 1\n",
    "\n",
    "average_activity_accuracy = np.mean(activity_accuracy)\n",
    "average_social_signal_accuracy = np.mean(social_signal_accuracy)\n",
    "\n",
    "# Convert the lists for the confusion matrix to numpy arrays\n",
    "all_y_true_social_signal = np.array(all_y_true_social_signal)\n",
    "all_y_pred_social_signal = np.array(all_y_pred_social_signal)\n",
    "\n",
    "print(f\"Average Activity Accuracy: {average_activity_accuracy:.4f}\")\n",
    "print(f\"Average Social Signal Accuracy: {average_social_signal_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c0cabfc4d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_y_true_social_signal, all_y_pred_social_signal)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Normal', 'Coughing', 'Hypervent', 'Other']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHNzGOHDtnQ4"
   },
   "source": [
    "# Exporting your model to TFLite\n",
    "\n",
    "You can use the TFLiteConverter class provided by TensorFlow to convert your trained model into the TensorFlow Lite format. We export models to TensorFlow Lite (TFLite) for several reasons, primarily because TFLite is designed for deployment on edge devices, such as mobile phones, embedded systems, IoT devices, and microcontrollers, where computational resources and power are limited. This is necessary as you will be running your ML models on your Android devices to perform live classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_QKoJtmufDa",
    "outputId": "48d281ab-4ed3-4ee1-fd47-30f7f4c10b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpl4aqxetw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpl4aqxetw\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpl4aqxetw'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 3), dtype=tf.float32, name='keras_tensor_85')\n",
      "Output Type:\n",
      "  List[TensorSpec(shape=(None, 11), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  1927137419408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119591120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119598800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119598032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119592848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119591312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119586512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119595536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119585936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927264045200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927264047504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119586896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119589008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927525979088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927525981968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927119590544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927264048464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model successfully exported to model.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model successfully exported to model.tflite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the accuracy of the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [22179, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m y_true_social_signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test_social_signal_one_hot, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m activity_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_activity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivity_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m social_signal_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true_social_signal, social_signal_predictions)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Print accuracy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [22179, 1]"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Placeholder lists for storing predictions\n",
    "activity_predictions = []\n",
    "social_signal_predictions = []\n",
    "\n",
    "# Run inference on each test sample\n",
    "for i in range(len(X_test)):\n",
    "    # Set the input tensor to the test sample\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output tensors\n",
    "    activity_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    social_signal_output = interpreter.get_tensor(output_details[1]['index'])\n",
    "\n",
    "    # Convert output to class predictions\n",
    "    activity_pred = np.argmax(activity_output, axis=1)[0]\n",
    "    social_signal_pred = np.argmax(social_signal_output, axis=1)[0]\n",
    "\n",
    "\n",
    "    # Append the predictions to the output lists\n",
    "    activity_predictions.append(activity_pred)\n",
    "    social_signal_predictions.append(social_signal_pred)\n",
    "\n",
    "    # Convert one-hot encoded labels to class labels\n",
    "    y_true_activity = np.argmax(y_test_activity_one_hot, axis=1)\n",
    "    y_true_social_signal = np.argmax(y_test_social_signal_one_hot, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    activity_accuracy = accuracy_score(y_true_activity, activity_predictions)\n",
    "    social_signal_accuracy = accuracy_score(y_true_social_signal, social_signal_predictions)\n",
    "\n",
    "    # Print accuracy\n",
    "    print(f\"Activity Accuracy: {activity_accuracy:.4f}\")\n",
    "    print(f\"Social Signal Accuracy: {social_signal_accuracy:.4f}\")\n",
    "\n",
    "    # Generate and print classification reports\n",
    "    report_activity = classification_report(y_true_activity, activity_predictions, output_dict=True)\n",
    "    report_social_signal = classification_report(y_true_social_signal, social_signal_predictions, output_dict=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
