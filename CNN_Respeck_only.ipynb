{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzd9Z9OZxNvd"
   },
   "source": [
    "# **Machine Learning Model**\n",
    "\n",
    "This notebook implements a convolutional neural network to recognise different physical activities from Respeck sensor data. The dataset includes multiple 30-second recordings of various physical activities (e.g., ascending stairs, shuffle walking, sitting-standing) stored in separate CSV files for each activity.\n",
    "\n",
    "This model will be deployed inside the Android app for live classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXyHZD1A0X7J"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s2B8Hymdj1Sg"
   },
   "outputs": [],
   "source": [
    "# Importing libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icbrBf1Kl6vp"
   },
   "source": [
    "# Reading Files\n",
    "Reading files from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pTsJd33Kl44J"
   },
   "outputs": [],
   "source": [
    "# Path to Respeck data\n",
    "your_dataset_path = \"./PDIoT2324/Respeck/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOTe3o9Il4ST"
   },
   "source": [
    "This line uses the glob module to find all file paths that match a specified pattern. The 'glob.glob()' function returns a list of file paths that match the given pattern. `your_dataset_path` should be the directory where your dataset files are located.\n",
    "\n",
    "The `*` is a wildcard character that matches any string of characters,  so this pattern retrieves all folders in the 'your_dataset_path' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4izGxKkllz6",
    "outputId": "49f7031e-36ae-454a-a8dc-4a7e92243315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PDIoT2324/Respeck\\\\s100_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s100_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s101_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s102_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s10_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s11_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s12_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s13_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s14_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s15_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s16_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s17_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s18_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s1_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s20_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s21_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s22_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s23_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s24_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s26_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s27_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s28_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_sitting_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s29_respeck_standing_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_ascending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_descending_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingBack_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingLeft_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingRight_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_hyperventilating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_laughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_singing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_lyingStomach_talking.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_miscMovement_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_normalWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_running_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_shuffleWalking_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_breathingNormal.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_coughing.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_eating.csv',\n",
       " './PDIoT2324/Respeck\\\\s30_respeck_sitting_hyperventilating.csv',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(your_dataset_path + \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7eNuiHKmBuT"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zdg12YooOJF"
   },
   "source": [
    "## Load list of files in an activity folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activities and social signals with corresponding labels\n",
    "# Each key is the name of the physical activity, and the corresponding value is the numeric label\n",
    "# These labels will be used as the target variable for classification\n",
    "\n",
    "activities = {\n",
    "    'ascending': 0,\n",
    "    'shuffleWalking': 1,\n",
    "    'sittingStanding': 2,\n",
    "    'miscMovement': 3,\n",
    "    'normalWalking': 4,\n",
    "    'lyingBack': 5,\n",
    "    'lyingLeft': 6,\n",
    "    'lyingRight': 7,\n",
    "    'lyingStomach': 8,\n",
    "    'descending': 9,\n",
    "    'running': 10\n",
    "}\n",
    "\n",
    "social_signals = {\n",
    "    'breathingNormal': 0,\n",
    "    'coughing': 1,\n",
    "    'hyperventilating': 2,\n",
    "    'other': 3\n",
    "}\n",
    "\n",
    "activity_labels = list(activities.keys())\n",
    "social_signal_labels = list(social_signals.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b_ZtuAb64ZsD"
   },
   "outputs": [],
   "source": [
    "def load_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load all CSV files from a folder and return a list of file paths.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing CSV files.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of file paths for all CSV files in the folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty list to store the full file paths of the CSV files\n",
    "    file_paths = []\n",
    "\n",
    "    # Loop through all the files in the given folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file has a .csv extension (ignores other files)\n",
    "        if file_name.endswith('.csv'):\n",
    "            # Construct the full file path by joining the folder path and the file name\n",
    "            full_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Append the full file path to the file_paths list\n",
    "            file_paths.append(full_file_path)\n",
    "\n",
    "    # Return the complete list of CSV file paths\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUGBeBBn_L8"
   },
   "source": [
    "## Train and test set split from list of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `social_signal_train_files`, `social_signal_test_files`, `activity_train_files` and `activity_test_files` from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract either the activity or the social signal label from the file name\n",
    "def extract_task(file_name, task):\n",
    "    \"\"\"\n",
    "    Extract the activity or social signal label from a file name.\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): The name of the file containing the label.\n",
    "    task (str): The task to extract from the file name (e.g., 'activity' or 'social_signal').\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted label from the file name.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the file name by underscores to extract different parts\n",
    "    file_parts = file_name.split('_')\n",
    "\n",
    "    # Check if the task is 'activity'\n",
    "    if task == 'activity':\n",
    "        # The activity label is the second part of the file name\n",
    "        label = file_parts[2]\n",
    "    # Check if the task is 'social_signal'\n",
    "    elif task == 'social_signal':\n",
    "        # The social signal label is the third part of the file name\n",
    "        label = file_parts[3].split(\".\")[0]\n",
    "\n",
    "    if label == \"sitting\" or label == \"standing\":\n",
    "        label = \"sittingStanding\"\n",
    "\n",
    "    if label == \"laughing\" or label == \"talking\" or label == \"eating\" or label == \"singing\":\n",
    "        label = \"other\"\n",
    "\n",
    "    if task == \"activity\":\n",
    "        label = activities[label]\n",
    "    else:\n",
    "        label = social_signals[label]\n",
    "    # Return the extracted label\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "2SzHoQz2NH3v"
   },
   "outputs": [],
   "source": [
    "def split_files(file_list, task, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the list of files into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    file_list (list): List of file paths to be split into train and test sets.\n",
    "    test_size (float): The proportion of files to allocate to the test set.\n",
    "                       Default is 0.2, meaning 20% of the files will be used for testing.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - train_files (list): List of file paths for the training set.\n",
    "        - test_files (list): List of file paths for the test set.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for file in file_list:\n",
    "        label = extract_task(file, task)\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    train_files, test_files = train_test_split(file_list, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    # Return the train and test file lists\n",
    "    return train_files, test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J7-zQgZzP19"
   },
   "source": [
    "## Sliding Window\n",
    "\n",
    "In time series Activity Recognition, a sliding window is a commonly used technique to segment continuous sensor data (such as accelerometer readings) into smaller, fixed-length overlapping or non-overlapping time intervals, or windows. Each window contains a sequence of sensor measurements that represent a short period of time, and this segmented data is used to extract features or make predictions about the activity happening within that window.\n",
    "\n",
    "### Key Concepts of a Sliding Window\n",
    "1.   **Window Size:** This refers to the length of each segment or window, typically defined in terms of the number of time steps or the duration (e.g., 2 seconds). The window size should be chosen carefully to capture enough information about the activity without making the window too large.\n",
    "2.   **Step Size:** The step size determines how far the window moves forward after each step. If the step size is smaller than the window size, the windows will overlap. For example, if the window size is 5 seconds and the step size is 2 seconds, there will be a 3-second overlap between consecutive windows. Overlapping windows provide more data for analysis and can help smooth out predictions by capturing transitional activities.\n",
    "3.   **Non-Overlapping Windows:** If the step size is equal to the window size, the windows do not overlap. This method provides distinct segments of data but may miss transitional phases between activities.\n",
    "\n",
    "### Why Sliding Windows for Activity Recognition?\n",
    "\n",
    "* Segmentation of Continuous Data: Activity recognition systems work with continuous streams of sensor data, and the sliding window helps segment these into manageable pieces to classify activities within specific intervals.\n",
    "\n",
    "* Context Capturing: Human activities are often complex and spread across time. By using a sliding window, you can capture context across a short duration, which may include transitions or small fluctuations in the activity (e.g., a person moving from sitting to standing).\n",
    "\n",
    "* Feature Extraction: Within each window, features such as mean, variance, frequency domain features, etc., can be extracted to help classify the activity.\n",
    "\n",
    "* Real-Time Recognition: In real-time systems, the sliding window allows for continuous monitoring and updating of predictions as new data arrives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "u3SuHww6MpEx"
   },
   "outputs": [],
   "source": [
    "def load_and_apply_sliding_windows(file_paths, window_size, step_size, task):\n",
    "    \"\"\"\n",
    "    Load the data from each file, apply sliding windows, and return the windows and labels.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths to CSV files. Each file contains sensor data (e.g., accelerometer, gyroscope).\n",
    "    window_size (int): The size of each sliding window (number of time steps).\n",
    "    step_size (int): The step size (stride) between consecutive windows.\n",
    "    label (int or str): The label for the activity corresponding to the folder.\n",
    "                        This label will be assigned to each sliding window extracted from the data.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - windows (numpy.ndarray): A 3D array of sliding windows, where each window has the shape\n",
    "                                   (num_windows, window_size, num_features).\n",
    "        - labels (numpy.ndarray): A 1D array of labels, where each label corresponds to a sliding window.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store sliding windows and their corresponding labels\n",
    "    windows = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through each file in the provided file paths\n",
    "    for file_path in file_paths:\n",
    "        label = extract_task(file_path, task)\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Select the columns containing the necessary sensor data (acceleration and gyroscope readings)\n",
    "        # These columns might vary depending on your dataset's structure\n",
    "        data = data[['accel_x', 'accel_y', 'accel_z']]\n",
    "\n",
    "        # Convert the DataFrame into a numpy array for faster processing in the sliding window operation\n",
    "        data = data.to_numpy()\n",
    "\n",
    "        # Get the number of samples (rows) and features (columns) in the data\n",
    "        num_samples, num_features = data.shape\n",
    "\n",
    "        # Apply sliding windows to the data\n",
    "        # The range function defines the start of each window, moving step_size increments at a time\n",
    "        for i in range(0, num_samples - window_size + 1, step_size):\n",
    "            # Extract a window of size 'window_size' from the current position 'i'\n",
    "            window = data[i:i + window_size, :]\n",
    "\n",
    "            # Append the window to the windows list\n",
    "            windows.append(window)\n",
    "\n",
    "            # Assign the activity label to the window and append it to the labels list\n",
    "            labels.append(label)\n",
    "\n",
    "    # Convert the lists of windows and labels into numpy arrays for efficient numerical operations\n",
    "    return np.array(windows), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Ku5P4Lm8QA"
   },
   "source": [
    "## Load and Split Train Test for Each Activity Folder\n",
    "\n",
    "This function processes the sensor data for a specific activity, such as 'walking' or 'running', stored in its respective folder. It splits the data into training and testing sets, applies sliding windows, and labels the windows with the corresponding activity. This function can be used repeatedly for each activity to process and prepare data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "zBVvTBi7N_fh"
   },
   "outputs": [],
   "source": [
    "def process_task(task, label_list, dataset_path, window_size=50, step_size=50, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Processes an activity folder by loading the file list, splitting them into\n",
    "    train and test sets, and applying sliding windows to the files.\n",
    "\n",
    "    Args:\n",
    "        activity (str): Name of the activity (folder name). This refers to the specific physical activity\n",
    "                        like 'walking', 'running', etc.\n",
    "        label (int): Numeric label corresponding to the activity, used for classification.\n",
    "        dataset_path (str): Base path where the activity folders are located.\n",
    "        window_size (int): Size of the sliding window, i.e., the number of time steps included in each window.\n",
    "                           Default is 50.\n",
    "        step_size (int): Step size for the sliding window, i.e., how far the window moves along the data.\n",
    "                         Default is 50 (no overlap between windows).\n",
    "        test_size (float): Proportion of files to use for testing. Default is 0.2, meaning 20% of files will\n",
    "                           be allocated to the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - train_windows (numpy.ndarray): Sliding windows from the training files.\n",
    "            - train_labels (numpy.ndarray): Corresponding labels for the training windows.\n",
    "            - test_windows (numpy.ndarray): Sliding windows from the test files.\n",
    "            - test_labels (numpy.ndarray): Corresponding labels for the test windows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all CSV file paths for the given activity from the folder\n",
    "    file_list = load_files_from_folder(dataset_path)\n",
    "\n",
    "    # Split the file list into training and testing sets\n",
    "    # train_files: files used for training\n",
    "    # test_files: files used for testing\n",
    "    train_files, test_files = split_files(file_list, task, test_size=test_size)\n",
    "    \n",
    "    # Apply sliding windows to the training files\n",
    "    # The function 'load_and_apply_sliding_windows' returns the sliding windows (segments) and their corresponding labels\n",
    "    train_windows, train_labels = load_and_apply_sliding_windows(train_files, window_size, step_size, task)\n",
    "\n",
    "    # Apply sliding windows to the testing files\n",
    "    test_windows, test_labels = load_and_apply_sliding_windows(test_files, window_size, step_size, task)\n",
    "\n",
    "    # Return the sliding windows and their labels for both training and testing sets\n",
    "    return train_windows, train_labels, test_windows, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data\n",
    "The function combines the sliding window data and their corresponding labels from multiple activities (e.g., walking, running, etc.) into single arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(train_test_data, data_type):\n",
    "    \"\"\"\n",
    "    Combines the sliding windows and labels from all activities into a single\n",
    "    array for either training or testing.\n",
    "\n",
    "    Args:\n",
    "        train_test_data (dict): Dictionary containing the sliding window data for all activities.\n",
    "                                Each key in the dictionary corresponds to an activity, and the value is another\n",
    "                                dictionary with the keys 'train_windows', 'train_labels', 'test_windows', 'test_labels'.\n",
    "        data_type (str): Either 'train' or 'test' to specify which data to combine (e.g., 'train_windows' or 'test_windows').\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - windows (numpy.ndarray): Concatenated windows from all activities for either training or testing.\n",
    "            - labels (numpy.ndarray): Concatenated labels corresponding to the windows from all activities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the list of sliding windows for the specified data type (either 'train' or 'test') from each activity\n",
    "    # For example, if data_type is 'train', it extracts 'train_windows' for all activities\n",
    "    windows_list = [train_test_data[activity][f'{data_type}_windows'] for activity in train_test_data]\n",
    "\n",
    "    # Similarly, extract the list of labels corresponding to the windows for each activity\n",
    "    labels_list = [train_test_data[activity][f'{data_type}_labels'] for activity in train_test_data]\n",
    "\n",
    "    # Concatenate all the sliding windows into a single numpy array along the first axis (rows)\n",
    "    # This creates one large array of windows from all the activities combined\n",
    "    concatenated_windows = np.concatenate(windows_list, axis=0)\n",
    "\n",
    "    # Concatenate all the labels into a single numpy array along the first axis (rows)\n",
    "    # The labels are now aligned with the concatenated windows\n",
    "    concatenated_labels = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "    # Return the concatenated windows and labels as a tuple\n",
    "    return concatenated_windows, concatenated_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wv1PuOLgUV8"
   },
   "source": [
    "## 1D CNN Model\n",
    "\n",
    "This function, `build_1d_cnn_model`, creates and compiles a 1D Convolutional Neural Network (CNN) for multi-label classification tasks.\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "Input Parameters\n",
    "* `input_shape`: Specifies the shape of the input data. It represents (timesteps, features), where timesteps refer to the length of the time series (e.g., 50 windows), and features represent the number of measurements in each time step (e.g., accelerometer readings).\n",
    "* `num_activity_classes`: The number of output classes for the activity classification problem.\n",
    "* `num_social_signal_classes`: The number of output classes for the social signal classification problem.\n",
    "\n",
    "Returns\n",
    "* The function returns a compiled 1D CNN model with two outputs that is ready to be trained on your data.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Function Breakdown\n",
    "1. **Model Initialization:**\n",
    "    * `inputs = Input(shape=input_shape)`: Initializes the input layer with the specified shape.\n",
    "2. **First Convolutional Layer:**\n",
    "    * `Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)`\n",
    "        * This is the first 1D convolutional layer.\n",
    "        * `filters=64`: The layer applies 64 filters (or kernels) over the input data.\n",
    "        * `kernel_size=3`: Each filter will cover 3 timesteps at a time (a window of 3).\n",
    "        * `activation='relu'`: The Rectified Linear Unit (ReLU) activation function introduces non-linearity and helps the model learn complex patterns.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: This pooling layer reduces the dimensionality of the data by taking the maximum value from each 2-timestep window (`pool_size=2`).\n",
    "3. **Second Convolutional Layer:**\n",
    "    * `Conv1D(filters=128, kernel_size=3, activation='relu')(x)`\n",
    "        * This is the second convolutional layer, similar to the first, but with 128 filters.\n",
    "        * `kernel_size=3` and `activation='relu'` function in the same way as the first Conv1D layer.\n",
    "    * `MaxPooling1D(pool_size=2)(x)`: Another pooling layer to downsample the output, further reducing the datas dimensionality.\n",
    "4. **Flattening Layer:**\n",
    "    * `Flatten()(x)`: Converts the 2D output of the convolutional and pooling layers into a 1D vector.\n",
    "5. **Fully Connected Layer:**\n",
    "    * `Dense(128, activation='relu')(x)`: This is a fully connected layer with 128 units/neurons.\n",
    "6. **Dropout Layer:**\n",
    "    * `Dropout(0.5)(x)`: This layer randomly sets 50% of the neurons to zero during training to prevent overfitting.\n",
    "7. **Output Layer for Activity Classification:**\n",
    "    * `Dense(num_activity_classes, activation='softmax', name='activity_output')(x)`: This is the output layer for activity classification with `num_activity_classes` neurons.\n",
    "8. **Output Layer for Social Signal Classification:**\n",
    "    * `Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(x)`: This is the output layer for social signal classification with `num_social_signal_classes` neurons.\n",
    "9. **Model Definition:**\n",
    "    * `model = Model(inputs=inputs, outputs=[activity_output, social_signal_output])`: Defines the model with two outputs.\n",
    "10. **Compiling the Model:**\n",
    "    * `model.compile(optimizer='adam', loss={'activity_output': 'categorical_crossentropy', 'social_signal_output': 'categorical_crossentropy'}, metrics={'activity_output': 'accuracy', 'social_signal_output': 'accuracy'})`\n",
    "        * Optimizer: 'adam': Adam is an optimization algorithm that adjusts the learning rate during training to improve performance.\n",
    "        * Loss: 'categorical_crossentropy': This loss function is used for multi-class classification problems where the target variable is one-hot encoded.\n",
    "        * Metrics: ['accuracy']: The accuracy metric is used to evaluate the models performance during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "sCOkh99EOg8t"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_activity_model(input_shape, num_activity_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional and pooling layers\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Output layer for activity classification\n",
    "    activity_output = Dense(num_activity_classes, activation='softmax', name='activity_output')(x)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = Model(inputs=inputs, outputs=activity_output)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_social_signal_model(input_shape, num_social_signal_classes):\n",
    "    \"\"\"\n",
    "    Builds and compiles a 1D CNN model for social signal classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (timesteps, features).\n",
    "        num_social_signal_classes (int): The number of output social signal classes.\n",
    "    \n",
    "    Returns:\n",
    "        model (Model): Compiled 1D CNN model for social signal classification.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Shared Conv1D layers\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Additional Conv1D layers for social signal classification\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Flatten, fully connected layer, and output layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    social_signal_output = Dense(num_social_signal_classes, activation='softmax', name='social_signal_output')(x)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = Model(inputs=inputs, outputs=social_signal_output)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HurfE6lmOjQT"
   },
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLs1eacYoa_S"
   },
   "source": [
    "## Step 1: Prepare and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data for activity 48578 with 11 different labels\n",
      "Length of training data for social signal 48580 with 4 different labels\n",
      "Length of test data for activity is 12151 with 11 different labels\n",
      "Length of test data for social signal is 12149 with 4 different labels\n"
     ]
    }
   ],
   "source": [
    "X_train_activity, y_train_activity, X_test_activity, y_test_activity = process_task(\"activity\", activity_labels, your_dataset_path)\n",
    "X_train_social_signal, y_train_social_signal, X_test_social_signal, y_test_social_signal = process_task(\"social_signal\", social_signal_labels, your_dataset_path)\n",
    "\n",
    "print(f\"Length of training data for activity {len(X_train_activity)} with {len(set(y_train_activity))} different labels\")\n",
    "print(f\"Length of training data for social signal {len(X_train_social_signal)} with {len(set(y_train_social_signal))} different labels\")\t\n",
    "\n",
    "print(f\"Length of test data for activity is {len(X_test_activity)} with {len(set(y_test_activity))} different labels\")\n",
    "print(f\"Length of test data for social signal is {len(X_test_social_signal)} with {len(set(y_test_social_signal))} different labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdGR352hph4X"
   },
   "source": [
    "Now the training and testing data will be created by calling the function `process_activity`. The `process_activity` function is used to generate sliding windows and labels for the training and testing sets.\n",
    "* `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
    "* `y_train_activity` and `y_train_social_signal` are 1D arrays of activity and social signal labels for the training set.\n",
    "* `y_test_activity` and `y_test_social_signal` are 1D arrays of activity and social signal labels for the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training and testing sets generated by the `process_activity` function are checked to see that they have the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yQGU1vwIQdz"
   },
   "source": [
    "### One-Hot Encode Labels (for multi-class classification)\n",
    "Since there are more than two classes, the labels must be one-hot encoded, especially as the model will use categorical cross-entropy loss.\n",
    "\n",
    "One-Hot Encoding converts categorical labels into binary vectors (one-hot encoded format). Each class label is represented as a binary vector with 1 for the correct class and 0 for others. This is necessary for training models that use categorical_crossentropy as the loss function, such as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "9b2J1EVdHj0U"
   },
   "outputs": [],
   "source": [
    "# Initialise the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the OneHotEncoder on the training activity labels and transform them to one-hot encoded format\n",
    "y_train_activity_one_hot = encoder.fit_transform(y_train_activity.reshape(-1, 1))\n",
    "\n",
    "# Transform the test activity labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_activity_one_hot = encoder.transform(y_test_activity.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Fit the OneHotEncoder on the training social signal labels and transform them to one-hot encoded format\n",
    "y_train_social_signal_one_hot = encoder.fit_transform(y_train_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Transform the test social signal labels to one-hot encoded format using the already fitted encoder\n",
    "y_test_social_signal_one_hot = encoder.transform(y_test_social_signal.reshape(-1, 1))\n",
    "\n",
    "# Explanation:\n",
    "# - y_train_activity_one_hot, y_train_social_signal_one_hot, y_test_activity_one_hot and y_test_social_signal_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
    "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
    "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlnbOVr0rDbV",
    "outputId": "98ddbd62-4d6c-41ba-ac94-00d74a30f3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_activity_one_hot shape: (88697, 11), y_train_social_signal_one_hot shape: (88697, 4), y_test_activity_one_hot shape: (22179, 11), y_test_social_signal_one_hot shape: (22179, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
    "print(f\"y_train_activity_one_hot shape: {y_train_activity_one_hot.shape}, y_train_social_signal_one_hot shape: {y_train_social_signal_one_hot.shape}, y_test_activity_one_hot shape: {y_test_activity_one_hot.shape}, y_test_social_signal_one_hot shape: {y_test_social_signal_one_hot.shape}\")\n",
    "\n",
    "# Explanation of shapes:\n",
    "# - The shape of y_train_activity_one_hot will be (num_samples, num_classes), where:\n",
    "#     - num_samples is the number of training windows.\n",
    "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
    "# - Similarly, y_test_activity_one_hot will have the same number of columns (num_classes) as y_train_activity_one_hot but will have fewer rows (corresponding to the number of test windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEhUxZzzJzzI"
   },
   "source": [
    "## Step 2: Build the 1D-CNN Model\n",
    "Call our `build_1d_cnn_model` function to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "4sDZWZH_KKBD",
    "outputId": "12cc6048-0921-414c-d2d7-b8d5268a8196"
   },
   "outputs": [],
   "source": [
    "# Determine the input shape for the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Determine the number of output classes (num_classes)\n",
    "num_activity_classes = y_train_activity_one_hot.shape[1]\n",
    "num_social_signal_classes = y_train_social_signal_one_hot.shape[1]\n",
    "\n",
    "# Build and compile the model\n",
    "# The function will return a compiled model ready for training\n",
    "model = build_1d_cnn_model(input_shape, num_activity_classes, num_social_signal_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1-SHEmtKM0D"
   },
   "source": [
    "## Step 3: Train and Evaluate the CNN Model\n",
    "\n",
    "Train the 1D CNN model using the training data and validate on the test data. The model will learn to map input sliding windows to their corresponding activity and social signal labels.\n",
    "\n",
    "`model.fit()` is used to train the neural network model. It takes several parameters:\n",
    "* `X_train`: The input training data (sliding windows), with shape (num_samples, window_size, num_features).\n",
    "* `{'activity_output': y_train_activity_one_hot, 'social_signal_output': y_train_social_signal_one_hot}`: The corresponding one-hot encoded labels for the training data, with shape (num_samples, num_classes).\n",
    "* `epochs`: Number of times the entire training dataset is passed through the model. In this case, we are training for 20 epochs, meaning the model will see the entire training set 20 times.\n",
    "* `batch_size`: Number of samples processed before the model's weights are updated. Here, the batch size is set to 32, meaning the model will process 32 samples at a time before updating its parameters.\n",
    "* `validation_data`: This parameter allows us to evaluate the model's performance on the test data after each epoch. It takes the test data and corresponding one-hot encoded test labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model is evaluated on the test set. This is done with  5-Fold Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_accuracy` is the accuracy of the model on the validation data (in this case X_test, y_test_activity_one_hot and y_test_social_signal_one_hot). The `accuracy` is the training accuracy for the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Completed fold 1\n",
      "Training fold 2\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Completed fold 2\n",
      "Training fold 3\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Completed fold 3\n",
      "Training fold 4\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Completed fold 4\n",
      "Training fold 5\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m555/555\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Completed fold 5\n",
      "Average Activity Accuracy: 0.9301\n",
      "Average Social Signal Accuracy: 0.6110\n"
     ]
    }
   ],
   "source": [
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialise lists to store the accuracy of each fold\n",
    "activity_accuracy = []\n",
    "social_signal_accuracy = []\n",
    "\n",
    "# Initialise lists to store the true and predicted labels for social signals for all folds\n",
    "all_y_true_social_signal = []\n",
    "all_y_pred_social_signal = []\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    print(f\"Training fold {fold_no}\")\n",
    "\n",
    "    # Split the data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_activity_fold, y_val_activity_fold = y_train_activity_one_hot[train_index], y_train_activity_one_hot[val_index]\n",
    "    y_train_social_signal_fold, y_val_social_signal_fold = y_train_social_signal_one_hot[train_index], y_train_social_signal_one_hot[val_index]\n",
    "\n",
    "    # Train and evaluate Activity model\n",
    "    activity_model = build_activity_model(input_shape, num_activity_classes)\n",
    "    activity_model.fit(\n",
    "        X_train_fold, y_train_activity_fold,\n",
    "        epochs=2,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_fold, y_val_activity_fold),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions and evaluation for Activity model\n",
    "    y_pred_probs_activity = activity_model.predict(X_val_fold)\n",
    "    y_pred_activity = np.argmax(y_pred_probs_activity, axis=1)\n",
    "    y_true_activity = np.argmax(y_val_activity_fold, axis=1)\n",
    "    report_activity = classification_report(y_true_activity, y_pred_activity, output_dict=True)\n",
    "    activity_accuracy.append(report_activity['accuracy'])\n",
    "\n",
    "    # Train and evaluate Social Signal model\n",
    "    social_signal_model = build_social_signal_model(input_shape, num_social_signal_classes)\n",
    "    social_signal_model.fit(\n",
    "        X_train_fold, y_train_social_signal_fold,\n",
    "        epochs=2,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_fold, y_val_social_signal_fold),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions and evaluation for Social Signal model\n",
    "    y_pred_probs_social_signal = social_signal_model.predict(X_val_fold)\n",
    "    y_pred_social_signal = np.argmax(y_pred_probs_social_signal, axis=1)\n",
    "    y_true_social_signal = np.argmax(y_val_social_signal_fold, axis=1)\n",
    "    report_social_signal = classification_report(y_true_social_signal, y_pred_social_signal, output_dict=True)\n",
    "    social_signal_accuracy.append(report_social_signal['accuracy'])\n",
    "\n",
    "    # Collect predictions and true labels for confusion matrix\n",
    "    all_y_true_social_signal.extend(y_true_social_signal)\n",
    "    all_y_pred_social_signal.extend(y_pred_social_signal)\n",
    "\n",
    "    print(f\"Completed fold {fold_no}\")\n",
    "    fold_no += 1\n",
    "\n",
    "# Calculate average accuracy across folds\n",
    "average_activity_accuracy = np.mean(activity_accuracy)\n",
    "average_social_signal_accuracy = np.mean(social_signal_accuracy)\n",
    "\n",
    "# Convert the lists for the confusion matrix to numpy arrays\n",
    "all_y_true_social_signal = np.array(all_y_true_social_signal)\n",
    "all_y_pred_social_signal = np.array(all_y_pred_social_signal)\n",
    "\n",
    "print(f\"Average Activity Accuracy: {average_activity_accuracy:.4f}\")\n",
    "print(f\"Average Social Signal Accuracy: {average_social_signal_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1586101e720>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_y_true_social_signal, all_y_pred_social_signal)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Normal', 'Coughing', 'Hypervent', 'Other']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHNzGOHDtnQ4"
   },
   "source": [
    "# Exporting your model to TFLite\n",
    "\n",
    "You can use the TFLiteConverter class provided by TensorFlow to convert your trained model into the TensorFlow Lite format. We export models to TensorFlow Lite (TFLite) for several reasons, primarily because TFLite is designed for deployment on edge devices, such as mobile phones, embedded systems, IoT devices, and microcontrollers, where computational resources and power are limited. This is necessary as you will be running your ML models on your Android devices to perform live classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_QKoJtmufDa",
    "outputId": "48d281ab-4ed3-4ee1-fd47-30f7f4c10b96"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have trained your models and they are stored in `activity_model` and `social_signal_model`\n",
    "\n",
    "# Convert the activity model to TFLite\n",
    "def export_activity_model_to_tflite(activity_model, filename=\"activity_model.tflite\"):\n",
    "    # Create a TFLiteConverter object from the Keras model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(activity_model)\n",
    "    \n",
    "    # Convert the model\n",
    "    tflite_activity_model = converter.convert()\n",
    "    \n",
    "    # Save the converted model to a file\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(tflite_activity_model)\n",
    "    \n",
    "    print(f\"Activity model successfully exported to {filename}\")\n",
    "\n",
    "\n",
    "# Convert the social signal model to TFLite\n",
    "def export_social_signal_model_to_tflite(social_signal_model, filename=\"social_signal_model.tflite\"):\n",
    "    # Create a TFLiteConverter object from the Keras model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(social_signal_model)\n",
    "    \n",
    "    # Convert the model\n",
    "    tflite_social_signal_model = converter.convert()\n",
    "    \n",
    "    # Save the converted model to a file\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(tflite_social_signal_model)\n",
    "    \n",
    "    print(f\"Social signal model successfully exported to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpf7ue3myq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpf7ue3myq\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpf7ue3myq'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 3), dtype=tf.float32, name='keras_tensor_610')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 11), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1478995596624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478995605264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478995593936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478995593552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478995597584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478995595472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679314512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679329680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Activity model successfully exported to activity_model.tflite\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpoq3qd25q\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpoq3qd25q\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\seanc\\AppData\\Local\\Temp\\tmpoq3qd25q'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 3), dtype=tf.float32, name='keras_tensor_619')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1478679327760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679330256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679326032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679330640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679327376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679315856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679328528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679329296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478679327184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1478391096400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Social signal model successfully exported to social_signal_model.tflite\n"
     ]
    }
   ],
   "source": [
    "# Export both models to TFLite format\n",
    "export_activity_model_to_tflite(activity_model, \"activity_model.tflite\")\n",
    "export_social_signal_model_to_tflite(social_signal_model, \"social_signal_model.tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the accuracy of the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_activity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m activity_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run inference on each test sample\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mX_test_activity\u001b[49m)):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Set the input tensor to the test sample\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X_test_activity[i], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     20\u001b[0m     activity_interpreter\u001b[38;5;241m.\u001b[39mset_tensor(activity_input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], input_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_activity' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load TFLite model and allocate tensors\n",
    "activity_interpreter = tf.lite.Interpreter(model_path=\"activity_model.tflite\")\n",
    "activity_interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "activity_input_details = activity_interpreter.get_input_details()\n",
    "activity_output_details = activity_interpreter.get_output_details()\n",
    "\n",
    "# Placeholder list for storing predictions\n",
    "activity_predictions = []\n",
    "\n",
    "# Run inference on each test sample\n",
    "for i in range(len(X_test_activity)):\n",
    "    # Set the input tensor to the test sample\n",
    "    input_data = np.expand_dims(X_test_activity[i], axis=0).astype(np.float32)\n",
    "    activity_interpreter.set_tensor(activity_input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run inference\n",
    "    activity_interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    activity_output = activity_interpreter.get_tensor(activity_output_details[0]['index'])\n",
    "    \n",
    "    # Convert output to class prediction\n",
    "    activity_pred = np.argmax(activity_output, axis=1)[0]\n",
    "    activity_predictions.append(activity_pred)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "y_true_activity = np.argmax(y_test_activity_one_hot, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "activity_accuracy = accuracy_score(y_true_activity, activity_predictions)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Activity Model Accuracy: {activity_accuracy:.4f}\")\n",
    "print(\"Activity Model Classification Report:\", classification_report(y_true_activity, activity_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'social_signal_model.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load TFLite model and allocate tensors\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m social_signal_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msocial_signal_model.tflite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m social_signal_interpreter\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get input and output details\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seanc\\miniconda3\\envs\\pdiot\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:473\u001b[0m, in \u001b[0;36mInterpreter.__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering, experimental_default_delegate_latest_features)\u001b[0m\n\u001b[0;32m    467\u001b[0m custom_op_registerers_by_name \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    468\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    469\u001b[0m ]\n\u001b[0;32m    470\u001b[0m custom_op_registerers_by_func \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    471\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    472\u001b[0m ]\n\u001b[1;32m--> 473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43m_interpreter_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateWrapperFromFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_resolver_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_preserve_all_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_disable_delegate_clustering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_default_delegate_latest_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter:\n\u001b[0;32m    484\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to open \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_path))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not open 'social_signal_model.tflite'."
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "social_signal_interpreter = tf.lite.Interpreter(model_path=\"social_signal_model.tflite\")\n",
    "social_signal_interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "social_signal_input_details = social_signal_interpreter.get_input_details()\n",
    "social_signal_output_details = social_signal_interpreter.get_output_details()\n",
    "\n",
    "# Placeholder list for storing predictions\n",
    "social_signal_predictions = []\n",
    "\n",
    "# Run inference on each test sample\n",
    "for i in range(len(X_test_social_signal)):\n",
    "    # Set the input tensor to the test sample\n",
    "    input_data = np.expand_dims(X_test_social_signal[i], axis=0).astype(np.float32)\n",
    "    social_signal_interpreter.set_tensor(social_signal_input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run inference\n",
    "    social_signal_interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    social_signal_output = social_signal_interpreter.get_tensor(social_signal_output_details[0]['index'])\n",
    "    \n",
    "    # Convert output to class prediction\n",
    "    social_signal_pred = np.argmax(social_signal_output, axis=1)[0]\n",
    "    social_signal_predictions.append(social_signal_pred)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "y_true_social_signal = np.argmax(y_test_social_signal_one_hot, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "social_signal_accuracy = accuracy_score(y_true_social_signal, social_signal_predictions)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Social Signal Model Accuracy: {social_signal_accuracy:.4f}\")\n",
    "print(\"Social Signal Model Classification Report:\", classification_report(y_true_social_signal, social_signal_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
